
# -*- coding: utf-8 -*-
"""
AutoAlpha-style Evolutionary Search (GA) for Formulaic Alphas
================================================================
ë³¸ ëª¨ë“ˆì€ ë‹¤ìŒ ë…¼ë¬¸ì˜ ì•„ì´ë””ì–´(ê³„ì¸µì  íƒìƒ‰ + PCA-QD + Warm Start + Parent-Offspring Replacement)ë¥¼
ì‹¤ë¬´ ì½”ë“œë¡œ ì˜®ê¸´ MVP êµ¬í˜„ì…ë‹ˆë‹¤.

    AutoAlpha: an Efficient Hierarchical Evolutionary Algorithm for Mining Alpha Factors
    (Zhang et al., IJCAI 2020, arXiv:2002.08245)

ë³¸ êµ¬í˜„ì€ ë‹¤ìŒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.
- Alphas.pyì˜ ì—°ì‚°ì/ì…ë ¥(OHLCV, VWAP, returns ë“±)ì„ ì¬ì‚¬ìš©í•˜ì—¬ "ìˆ˜ì‹ íŠ¸ë¦¬" í˜•íƒœì˜ ì•ŒíŒŒë¥¼ ì§„í™”ì‹œí‚µë‹ˆë‹¤.
- AutoAlpha/AlphaMix ë…¼ë¬¸ì„ ì°¸ê³ í•´ ë‹¤ì¤‘ ê¸°ê°„ IC, ì •ë³´ë¹„ìœ¨(IC_IR), íšŒì „ìœ¨, PCA ë‹¤ì–‘ì„±ì„ ê²°í•©í•œ í•©ë¦¬ì  ìŠ¤ì½”ì–´ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
- PCA-QD + Age-Layered ì¬ì‹œì‘ ì „ëµìœ¼ë¡œ íƒìƒ‰ ë‹¤ì–‘ì„±ì„ ìœ ì§€í•˜ê³ , ìƒìœ„ í›„ë³´ë§Œ ë³„ë„ ë°±í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ(ì˜ˆ: 5_results.LongOnlyBacktestSystem)ì— ë„˜ê¸¸ ìˆ˜ ìˆë„ë¡ í›…ì„ ì œê³µí•©ë‹ˆë‹¤.
- ìµœì¢… ì„ ë³„ëœ ì•ŒíŒŒë¥¼ NewAlphas.pyì— í•¨ìˆ˜(alphaGA001, ...) í˜•íƒœë¡œ ìë™ ê¸°ë¡í•©ë‹ˆë‹¤.

ìš”êµ¬ë˜ëŠ” ë°ì´í„° í˜•ì‹ (ì¤‘ìš”):
- Alphas.Alphas ê°€ ê¸°ëŒ€í•˜ëŠ” ë™ì¼í•œ df_data êµ¬ì¡°ë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
  ì¦‰, ë”•ì…”ë„ˆë¦¬ ë˜ëŠ” ë„¤ì„ë“œ ê°ì²´ë¡œ ë‹¤ìŒ í‚¤ë¥¼ ê°€ì§„ pandas.DataFrame(ì¸ë±ìŠ¤: Date, ì»¬ëŸ¼: Ticker)ë“¤ì„ ì œê³µí•©ë‹ˆë‹¤.
    'S_DQ_OPEN', 'S_DQ_HIGH', 'S_DQ_LOW', 'S_DQ_CLOSE', 'S_DQ_VOLUME', 'S_DQ_PCTCHANGE', 'S_DQ_AMOUNT'
- ê° DataFrameì˜ shapeì€ (ì‹œê°„ x ì¢…ëª©) ì´ì–´ì•¼ í•˜ë©°, ì¸ë±ìŠ¤ëŠ” ì •ë ¬ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.

ë¹ ë¥¸ ì‹œì‘:
---------
from autoalpha_ga import AutoAlphaGA, DefaultSearchSpace, write_new_alphas_file
from Alphas import Alphas

# df_dataë¥¼ ì¤€ë¹„ (ì‚¬ìš©ì ë¡œë”ë¡œ ìƒì„±)
ga = AutoAlphaGA(df_data, hold_horizon=1, random_seed=42)

elites = ga.run(
    max_depth=3,
    population=60,
    generations=20,
    warmstart_k=4,          # Kë°° ìƒì„± í›„ ìƒìœ„ 1/Kë§Œ ì´ˆê¸° ê°œì²´êµ°ì— í¸ì…
    n_keep_per_depth=25,    # ê° depthì˜ ì—˜ë¦¬íŠ¸ ë³´ê´€ ìƒí•œ
    p_mutation=0.3,
    p_crossover=0.7,
)

# ìƒìœ„ Mê°œë¥¼ NewAlphas.pyë¡œ ê¸°ë¡
write_new_alphas_file(elites[:10], out_path="NewAlphas.py")

í†µí•© íŒ:
--------
- 5_results.LongOnlyBacktestSystem ê³¼ ì—°ë™í•˜ë ¤ë©´, write_new_alphas_file()ë¡œ NewAlphas.py ìƒì„± í›„
  ê¸°ì¡´ íŒŒì´í”„ë¼ì¸ì—ì„œ alpha íŒŒì¼ ìƒì„± ë‹¨ê³„ì— NewAlphas.NewAlphasì˜ ë©”ì„œë“œë“¤ì„ í˜¸ì¶œí•´ ê³„ì‚° ê²°ê³¼ë¥¼ CSVë¡œ ë‚´ë¦¬ë©´ ë©ë‹ˆë‹¤.
"""

from __future__ import annotations

import math
import random
import json
import dataclasses
from dataclasses import dataclass, field
from typing import Any, Callable, Dict, List, Optional, Tuple, Union

import os
import sys
import numpy as np
import pandas as pd

# ==========================================
# ê²½ë¡œ ì„¤ì •: ì´ íŒŒì¼ ê¸°ì¤€ ìƒëŒ€ê²½ë¡œë¡œ backend_module ì¶”ê°€
# - ì–´ë””ì„œ ì‹¤í–‰í•˜ë“  backend_module/Alphas.py ë¥¼ import ê°€ëŠ¥í•˜ê²Œ í•¨
# ==========================================
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(CURRENT_DIR)
BACKEND_MODULE_DIR = os.path.join(PROJECT_ROOT, 'backend_module')

# ê²½ë¡œ ì¡´ì¬ í™•ì¸ ë° ì¹œì ˆí•œ ì—ëŸ¬ ë©”ì‹œì§€
if not os.path.exists(BACKEND_MODULE_DIR):
    raise ImportError(f"backend_module ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {BACKEND_MODULE_DIR}\n"
                     f"í”„ë¡œì íŠ¸ êµ¬ì¡°ë¥¼ í™•ì¸í•˜ê±°ë‚˜ PYTHONPATHë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")

if BACKEND_MODULE_DIR not in sys.path:
    sys.path.insert(0, BACKEND_MODULE_DIR)

# Alphas.pyì˜ ì—°ì‚°ì/ì…ë ¥ê³¼ ë™ì¼ í™˜ê²½ì—ì„œ ê³„ì‚°í•˜ê¸° ìœ„í•´ import (backend_module ë‚´ ìœ„ì¹˜)
from Alphas import (
    Alphas,
    ts_sum, sma, stddev, correlation, covariance,
    ts_rank, product, ts_min, ts_max, delta, delay, rank, scale,
    ts_argmax, ts_argmin, decay_linear,
    safe_clean, adv, floor_window
)


# ===============================
# í‘œí˜„: ìˆ˜ì‹ íŠ¸ë¦¬ (Expression Tree)
# ===============================

# ì—°ì‚°ì ë©”íƒ€ ì •ì˜
def _safe_divide(a: Union[pd.DataFrame, pd.Series, np.ndarray, float, int],
                 b: Union[pd.DataFrame, pd.Series, np.ndarray, float, int]) -> Union[pd.DataFrame, pd.Series, np.ndarray]:
    """
    Pandas Series/DataFrame ë˜ëŠ” numpy ë°°ì—´ì„ ì•ˆì „í•˜ê²Œ ë‚˜ëˆ•ë‹ˆë‹¤.
    - 0 ë‚˜ëˆ—ì…ˆ ë° inf ê°’ì„ NaNìœ¼ë¡œ ì •ë¦¬
    - ì…ë ¥ íƒ€ì…ì„ ìœ ì§€í•´ ë°˜í™˜
    """
    if hasattr(a, "align") and hasattr(b, "align"):
        a_aligned, b_aligned = a.align(b, join="outer")
    else:
        a_aligned, b_aligned = a, b

    a_vals = a_aligned.values if hasattr(a_aligned, "values") else np.asarray(a_aligned)
    b_vals = b_aligned.values if hasattr(b_aligned, "values") else np.asarray(b_aligned)

    with np.errstate(divide="ignore", invalid="ignore"):
        out = np.divide(a_vals, b_vals)
    out = np.where(np.isfinite(out), out, np.nan)

    if hasattr(a_aligned, "index"):
        if hasattr(a_aligned, "columns"):
            columns = a_aligned.columns if hasattr(a_aligned, "columns") else getattr(b_aligned, "columns", None)
            return pd.DataFrame(out, index=a_aligned.index, columns=columns)
        return pd.Series(out, index=a_aligned.index)
    return out


UNARY_OPS = {
    "rank": {"fn": rank, "params": []},
    "ts_rank": {"fn": ts_rank, "params": ["window"]},
    "delta": {"fn": delta, "params": ["period"]},
    "delay": {"fn": delay, "params": ["period"]},
    "sma": {"fn": sma, "params": ["window"]},
    "stddev": {"fn": stddev, "params": ["window"]},
    "ts_max": {"fn": ts_max, "params": ["window"]},
    "ts_min": {"fn": ts_min, "params": ["window"]},
    "ts_argmax": {"fn": ts_argmax, "params": ["window"]},
    "ts_argmin": {"fn": ts_argmin, "params": ["window"]},
    "decay_linear": {"fn": decay_linear, "params": ["period"], "frame_only": True},
}

BINARY_OPS = {
    "add": {"symbol": "+", "fn": lambda a, b: a + b},
    "sub": {"symbol": "-", "fn": lambda a, b: a - b},
    "mul": {"symbol": "*", "fn": lambda a, b: a * b},
    "div": {"symbol": "/", "fn": _safe_divide},
    "min": {"symbol": "min", "fn": lambda a, b: pd.DataFrame(np.minimum(a.values, b.values), index=a.index, columns=a.columns) if hasattr(a, 'index') and hasattr(b, 'index') else np.minimum(a, b)},
    "max": {"symbol": "max", "fn": lambda a, b: pd.DataFrame(np.maximum(a.values, b.values), index=a.index, columns=a.columns) if hasattr(a, 'index') and hasattr(b, 'index') else np.maximum(a, b)},
    "correlation": {"symbol": "correlation", "fn": correlation, "params": ["window"]},
}

TERMINALS = ["open", "high", "low", "close", "volume", "vwap", "returns"]

# ì§„í™” í’ˆì§ˆ í‰ê°€ ì‹œ ê¸°ë³¸ ê°€ì¤‘ì¹˜ ì„¤ì • (ë¬¸í—Œ ê¸°ë°˜)
DEFAULT_METRIC_WEIGHTS: Dict[str, Any] = {
    # ë‹¤ì¤‘ íˆ¬ì ê¸°ê°„ IC ì¤‘ìš”ë„ë¥¼ ë‹¨ê³„ì ìœ¼ë¡œ ë¶€ì—¬ (AutoAlpha + GEP ë…¼ë¬¸ ì¡°í•©)
    "horizons": {
        1: 0.4,
        5: 0.35,
        10: 0.25,
    },
    # ì•ˆì •ì„±ê³¼ ë‹¤ì–‘ì„± ë°˜ì˜ ê°€ì¤‘ì¹˜ (PCA-QD, Risk-aware GA ì°¸ê³ )
    "ic_ir": 0.25,
    "novelty": 0.15,
    "turnover": 0.1,
    "ic_vol": 0.1,
    "penalty": 0.1,
    # ì¶©ë¶„í•œ ì‹œê³„ì—´ ì»¤ë²„ë¦¬ì§€ í™•ë³´ë¥¼ ìœ„í•œ ëª©í‘œì¹˜
    "coverage_target": 0.6,
}


@dataclass
class Node:
    op: str
    left: Optional['Node'] = None
    right: Optional['Node'] = None
    params: Dict[str, Any] = field(default_factory=dict)
    terminal_name: Optional[str] = None

    def depth(self) -> int:
        if self.op == "terminal":
            return 1
        dl = self.left.depth() if self.left else 0
        dr = self.right.depth() if self.right else 0
        return 1 + max(dl, dr)

    def copy(self) -> 'Node':
        return Node(
            op=self.op,
            left=self.left.copy() if self.left else None,
            right=self.right.copy() if self.right else None,
            params=dict(self.params),
            terminal_name=self.terminal_name
        )

    def compile(self) -> Callable[[Alphas], pd.Series]:
        """
        ìˆ˜ì‹ íŠ¸ë¦¬ë¥¼ ì‹¤í–‰ ê°€ëŠ¥í•œ í•¨ìˆ˜ë¡œ ì»´íŒŒì¼í•©ë‹ˆë‹¤.
        - ë°˜í™˜ í•¨ìˆ˜ëŠ” Alphas ì»¨í…ìŠ¤íŠ¸(ê°€ê²©/ê±°ë˜ëŸ‰ ë“±)ë¥¼ ë°›ì•„ íŒ©í„° ì‹œê³„ì—´(Series ë˜ëŠ” DataFrame)ì„ ì¶œë ¥í•©ë‹ˆë‹¤.
        - ê³„ì‚° ê²°ê³¼ì˜ inf/NaNì€ 0ìœ¼ë¡œ ì •ë¦¬í•˜ì—¬ ì•ˆì •ì„± í™•ë³´.
        """
        def _compile(node: 'Node') -> Callable[[Alphas], pd.Series]:
            if node.op == "terminal":
                name = node.terminal_name
                def f(ctx: Alphas):
                    return getattr(ctx, name)
                return f

            if node.op in UNARY_OPS:
                fn_meta = UNARY_OPS[node.op]
                child_f = _compile(node.left)
                def f(ctx: Alphas):
                    x = child_f(ctx)
                    if fn_meta.get("frame_only"):
                        return fn_meta["fn"](x.to_frame(), **node.params).iloc[:, 0]
                    return fn_meta["fn"](x, **node.params)
                return f

            if node.op in BINARY_OPS:
                fn_meta = BINARY_OPS[node.op]
                left_f = _compile(node.left)
                right_f = _compile(node.right)
                if node.op == "correlation":
                    w = int(node.params.get("window", 10))
                    def f(ctx: Alphas):
                        a = left_f(ctx); b = right_f(ctx)
                        base_index = getattr(ctx.close, "index", None)
                        base_columns = getattr(ctx.close, "columns", None)
                        try:
                            if hasattr(a, "align") and hasattr(b, "align"):
                                a, b = a.align(b, join="inner", axis=0)
                                if hasattr(a, "columns") and hasattr(b, "columns"):
                                    a, b = a.align(b, join="inner", axis=1)
                        except Exception:
                            pass

                        if hasattr(a, "empty") and a.empty:
                            return pd.DataFrame(0, index=base_index, columns=base_columns)
                        if hasattr(b, "empty") and b.empty:
                            return pd.DataFrame(0, index=base_index, columns=base_columns)
                        try:
                            result = fn_meta["fn"](a, b, w)
                            # correlation ê²°ê³¼ ì•ˆì „ì„± í™•ë³´
                            if hasattr(result, 'replace'):
                                result = result.replace([np.inf, -np.inf], 0).fillna(0)
                            return result
                        except:
                            # correlation ê³„ì‚° ì‹¤íŒ¨ ì‹œ 0 í–‰ë ¬ ë°˜í™˜
                            return pd.DataFrame(0, index=base_index, columns=base_columns)
                    return f

                def f(ctx: Alphas):
                    a = left_f(ctx); b = right_f(ctx)
                    return fn_meta["fn"](a, b)
                return f

            raise ValueError(f"Unknown op: {node.op}")

        f = _compile(self)

        def safe(ctx: Alphas) -> pd.Series:
            out = f(ctx)
            if isinstance(out, (pd.DataFrame, pd.Series)):
                out = out.replace([np.inf, -np.inf], 0).fillna(0)
            return out
        return safe

    def to_python_expr(self) -> str:
        """
        í˜„ì¬ ìˆ˜ì‹ íŠ¸ë¦¬ë¥¼ Python í‘œí˜„ì‹ ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        - ìƒì„±ëœ ë¬¸ìì—´ì€ NewAlphas.py ë‚´ ê°œë³„ ë©”ì„œë“œ ë³¸ë¬¸ì—ì„œ ê·¸ëŒ€ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.
        - ì¼ë¶€ ì—°ì‚°ì(ì˜ˆ: decay_linear, correlation)ëŠ” í”„ë ˆì„/ìœˆë„ìš° ì¸ìë¥¼ ë§ì¶° ì²˜ë¦¬í•©ë‹ˆë‹¤.
        """
        if self.op == "terminal":
            return f"self.{self.terminal_name}"

        if self.op in UNARY_OPS:
            child = self.left.to_python_expr()
            if self.op in ("ts_rank", "sma", "stddev", "ts_max", "ts_min", "ts_argmax", "ts_argmin"):
                w = int(self.params.get("window") or self.params.get("period", 10))
                return f"{self.op}({child}, {w})"
            if self.op in ("delta", "delay"):
                p = int(self.params.get("period", 1))
                return f"{self.op}({child}, {p})"
            if self.op == "rank":
                return f"rank({child})"
            if self.op == "decay_linear":
                p = int(self.params.get('period', 10))
                return f"decay_linear({child}.to_frame(), {p}).iloc[:, 0]"
            return f"{self.op}({child})"

        if self.op in BINARY_OPS:
            left = self.left.to_python_expr()
            right = self.right.to_python_expr()
            if self.op == "correlation":
                w = int(self.params.get("window", 10))
                return f"correlation({left}, {right}, {w})"
            sym = BINARY_OPS[self.op]["symbol"]
            if sym in {"+", "-", "*", "/"}:
                return f"({left} {sym} {right})"
            if sym == "min":
                return f"pd.DataFrame(np.minimum(({left}).values, ({right}).values), index=({left}).index, columns=({left}).columns)"
            if sym == "max":
                return f"pd.DataFrame(np.maximum(({left}).values, ({right}).values), index=({left}).index, columns=({left}).columns)"
        raise ValueError(f"Unknown op {self.op}")

    def iter_nodes(self):
        yield self
        if self.left: 
            yield from self.left.iter_nodes()
        if self.right:
            yield from self.right.iter_nodes()


@dataclass
class FitnessMetrics:
    """
    ë‹¤ì¤‘ ì§€í‘œ ê¸°ë°˜ ì í•©ë„ ê²°ê³¼.
    - ic_by_horizon: ê¸°ê°„ë³„ í‰ê·  IC
    - ic_counts: ê¸°ê°„ë³„ ìœ íš¨ ì¼ì ìˆ˜
    - ic_volatility: ê¸°ê°„ í˜¼í•© ICì˜ ë³€ë™ì„±
    - ic_ir: ì •ë³´ë¹„ìœ¨
    - turnover: ìˆœìœ„ ë³€ë™ë¥  ê¸°ë°˜ íšŒì „ìœ¨
    - coverage: ìœ íš¨ ì¼ì ë¹„ìœ¨
    - novelty: PCA ê¸°ë°˜ ë‹¤ì–‘ì„± ì ìˆ˜
    - penalty: ì»¤ë²„ë¦¬ì§€/ì•ˆì •ì„± í˜ë„í‹° í•©ì‚°
    - composite: ìµœì¢… ìŠ¤ì¹¼ë¼ ì ìˆ˜
    """
    ic_by_horizon: Dict[int, float] = field(default_factory=dict)
    ic_counts: Dict[int, int] = field(default_factory=dict)
    ic_aggregate: float = float("nan")
    ic_volatility: float = float("nan")
    ic_ir: float = float("nan")
    turnover: float = float("nan")
    coverage: float = float("nan")
    novelty: float = float("nan")
    penalty: float = 0.0
    composite: float = float("nan")


class DefaultSearchSpace:
    """
    íƒìƒ‰ ê³µê°„ ì •ì˜ í´ë˜ìŠ¤
    - ì´ˆê¸° ë£¨íŠ¸ í…œí”Œë¦¿, ì‚¬ìš© ê°€ëŠ¥í•œ ë‹¨í•­/ì´í•­ ì—°ì‚°ì, ìœˆë„ìš° í›„ë³´ ë“±ì„ ë³´ìœ í•©ë‹ˆë‹¤.
    - ê²€ìƒ‰ ë‚œì´ë„/ë‹¤ì–‘ì„±ì„ ì¡°ì ˆí•˜ë ¤ë©´ í’€ ë˜ëŠ” ìœˆë„ìš° ë¶„í¬ë¥¼ ìˆ˜ì •í•˜ì„¸ìš”.
    """
    WINDOW_CANDIDATES = [3,5,10,20,30,60,120]
    ROOT_TEMPLATES: List[Node] = [
        Node(op="terminal", terminal_name="vwap"),
        Node(op="terminal", terminal_name="close"),
        Node(op="terminal", terminal_name="open"),
        Node(op="terminal", terminal_name="high"),
        Node(op="terminal", terminal_name="low"),
        Node(op="terminal", terminal_name="volume"),
        Node(op="div", left=Node(op="terminal", terminal_name="vwap"), right=Node(op="terminal", terminal_name="close")),
        Node(op="sub", left=Node(op="terminal", terminal_name="close"), right=Node(op="terminal", terminal_name="open")),
        Node(op="sub", left=Node(op="terminal", terminal_name="high"),  right=Node(op="terminal", terminal_name="low")),
    ]

    UNARY_POOL = ["rank", "ts_rank", "delta", "delay", "sma", "stddev", "ts_max", "ts_min", "ts_argmax", "ts_argmin", "decay_linear"]
    BINARY_POOL = ["add", "sub", "mul", "div", "min", "max", "correlation"]

    @classmethod
    def random_window(cls, rng: random.Random) -> int:
        return int(rng.choice(cls.WINDOW_CANDIDATES))


def compute_future_returns(close_df: pd.DataFrame, h: int) -> pd.DataFrame:
    """hì¼ ë’¤ ìˆ˜ìµë¥ ì„ ê³„ì‚°í•©ë‹ˆë‹¤: Close[t+h]/Close[t]-1"""
    return close_df.shift(-h) / close_df - 1.0

def cross_sectional_ic(factor: pd.DataFrame, future_ret: pd.DataFrame, show_progress: bool = False) -> float:
    """
    ë‹¨ë©´ IC(Information Coefficient)ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    - ê° ì¼ìë³„ë¡œ ì¢…ëª© ë‹¨ë©´ ìƒê´€ê³„ìˆ˜ë¥¼ êµ¬í•œ ë’¤ í‰ê· í•©ë‹ˆë‹¤.
    - ë°ì´í„° ì •í•©ì„±(ê³µí†µ ì¸ë±ìŠ¤) ë° ìœ íš¨ í‘œë³¸ ìˆ˜(>=5)ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
    """
    try:
        ic_series = cross_sectional_ic_series(factor, future_ret)
        if ic_series.empty:
            return float("nan")
        return float(ic_series.mean())
    except Exception:
        return float("nan")


def cross_sectional_ic_series(factor: pd.DataFrame, future_ret: pd.DataFrame) -> pd.Series:
    """
    ì¼ìë³„ ë‹¨ë©´ IC ì‹œê³„ì—´ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    - factor, future_ret: ë™ì¼í•œ ì¸ë±ìŠ¤(Date)ì™€ ì»¬ëŸ¼(Ticker)ì„ ê°€ì •
    """
    common = factor.index.intersection(future_ret.index)
    if len(common) == 0:
        return pd.Series(dtype=float)

    factor = factor.loc[common]
    future_ret = future_ret.loc[common]
    ic_values: List[float] = []
    ic_dates: List[pd.Timestamp] = []

    for dt, row in factor.iterrows():
        y = future_ret.loc[dt]
        x = row.values
        y_arr = y.values if hasattr(y, "values") else np.asarray(y)

        mask = np.isfinite(x) & np.isfinite(y_arr)
        if mask.sum() < 5:
            continue

        x_valid = x[mask]
        y_valid = y_arr[mask]

        if np.std(x_valid) < 1e-8 or np.std(y_valid) < 1e-8:
            continue

        try:
            corr_matrix = np.corrcoef(x_valid, y_valid)
            if corr_matrix.shape == (2, 2):
                ic_val = corr_matrix[0, 1]
                if np.isfinite(ic_val):
                    ic_values.append(float(ic_val))
                    ic_dates.append(dt)
        except Exception:
            continue

    if not ic_values:
        return pd.Series(dtype=float)
    return pd.Series(ic_values, index=pd.Index(ic_dates, name="date"))


def compute_factor_turnover(factor_df: pd.DataFrame) -> float:
    """
    íŒ©í„° ìˆœìœ„ ê¸°ë°˜ íšŒì „ìœ¨ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    - ì—°ì† ì¼ìì˜ ìˆœìœ„ ë³€í™”ëŸ‰ í‰ê· ì„ í†µí•´ ì•ˆì •ì„±ì„ ì¸¡ì •í•©ë‹ˆë‹¤.
    - ìˆœìœ„ ë³€í™” ì´í•©ì„ ìœ íš¨ ì¢…ëª© ìˆ˜ë¡œ ì •ê·œí™”í•˜ì—¬ 0~2 ë²”ìœ„ë¥¼ ê¸°ëŒ€í•©ë‹ˆë‹¤.
    """
    if factor_df.empty:
        return 0.0

    try:
        ranks = factor_df.rank(axis=1, method="average", pct=True)
        diffs = ranks.diff().abs()
        if diffs.shape[0] <= 1:
            return 0.0

        denom = ranks.notna().sum(axis=1).replace(0, np.nan)
        turnover_series = diffs.sum(axis=1) / denom
        turnover_series = turnover_series.replace([np.inf, -np.inf], np.nan).dropna()
        if turnover_series.empty:
            return 0.0
        return float(turnover_series.mean())
    except Exception:
        return 0.0

def first_pc_vector(A: pd.DataFrame) -> np.ndarray:
    """
    PCAì˜ ì²« ë²ˆì§¸ ì£¼ì„±ë¶„ ë²¡í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    - ê²°ì¸¡/ë¬´í•œê°’ì€ 0ìœ¼ë¡œ ì •ë¦¬ í›„ í‰ê·  ì œê±°
    - ìì‚° ì¶•(ì»¬ëŸ¼) ë¡œë”© ë²¡í„°ë¥¼ ë¹„êµ ëŒ€ìƒìœ¼ë¡œ ì‚¬ìš©
    - SVD ì‹¤íŒ¨ ì‹œ ë‹¨ìœ„ ë²¡í„°ë¡œ ëŒ€ì²´
    """
    X = A.values
    X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)
    X = X - X.mean(axis=0, keepdims=True)
    try:
        _, _, Vt = np.linalg.svd(X, full_matrices=False)
        v = Vt[0] if Vt.size > 0 else np.ones(X.shape[1], dtype=float)
        v = v / (np.linalg.norm(v) + 1e-12)
        return v
    except np.linalg.LinAlgError:
        if X.shape[1] == 0:
            return np.array([1.0])
        v = np.ones(X.shape[1], dtype=float)
        v /= np.linalg.norm(v) + 1e-12
        return v

def pca_similarity(A: pd.DataFrame, B: pd.DataFrame) -> float:
    """ë‘ í–‰ë ¬ì˜ 1ì£¼ì„±ë¶„ ë²¡í„° ê°„ ìƒê´€ê³„ìˆ˜(ìœ ì‚¬ë„)ë¥¼ ë°˜í™˜"""
    v1 = first_pc_vector(A)
    v2 = first_pc_vector(B)
    return float(np.corrcoef(v1, v2)[0,1])


def random_terminal(rng: random.Random) -> Node:
    """ë¬´ì‘ìœ„ ì…ë ¥ ë‹¨ë§ ë…¸ë“œ ìƒì„±(OHLCV, vwap, returns)"""
    t = rng.choice(TERMINALS)
    return Node(op="terminal", terminal_name=t)

def random_unary(rng: random.Random, child: Node) -> Node:
    """ë¬´ì‘ìœ„ ë‹¨í•­ ì—°ì‚°ì ë…¸ë“œ ìƒì„±(ìœˆë„ìš°/ê¸°ê°„ íŒŒë¼ë¯¸í„° í¬í•¨)"""
    op = rng.choice(DefaultSearchSpace.UNARY_POOL)
    params = {}
    if op in ("ts_rank", "sma", "stddev", "ts_max", "ts_min", "ts_argmax", "ts_argmin"):
        params["window"] = DefaultSearchSpace.random_window(rng)
    if op in ("delta", "delay"):
        params["period"] = DefaultSearchSpace.random_window(rng)
    if op == "decay_linear":
        params["period"] = DefaultSearchSpace.random_window(rng)
    return Node(op=op, left=child.copy(), params=params)

def random_binary(rng: random.Random, left: Node, right: Node) -> Node:
    """ë¬´ì‘ìœ„ ì´í•­ ì—°ì‚°ì ë…¸ë“œ ìƒì„±(correlationì˜ ê²½ìš° ìœˆë„ìš° í¬í•¨)"""
    op = rng.choice(DefaultSearchSpace.BINARY_POOL)
    params = {}
    if op == "correlation":
        params["window"] = DefaultSearchSpace.random_window(rng)
    return Node(op=op, left=left.copy(), right=right.copy(), params=params)

def random_tree(rng: random.Random, target_depth:int) -> Node:
    """ëª©í‘œ ê¹Šì´ì— ë§ì¶° ë¬´ì‘ìœ„ ìˆ˜ì‹ íŠ¸ë¦¬ ìƒì„±(ë‹¨í•­/ì´í•­ í˜¼í•©)"""
    if target_depth <= 1:
        return random_terminal(rng)
    if rng.random() < 0.5:
        child = random_tree(rng, target_depth-1)
        return random_unary(rng, child)
    else:
        left_depth = rng.randint(1, target_depth-1)
        right_depth = target_depth-1
        left = random_tree(rng, left_depth)
        right = random_tree(rng, right_depth)
        return random_binary(rng, left, right)

def mutate(rng: random.Random, node: Node, p_param: float=0.5) -> Node:
    """
    ë³€ì´ ì—°ì‚°
    - ì—°ì‚°ì êµì²´, íŒŒë¼ë¯¸í„° ì„­ë™, ì„œë¸ŒíŠ¸ë¦¬ ì¹˜í™˜ ì¤‘ í•˜ë‚˜ë¥¼ ë¬´ì‘ìœ„ ì„ íƒ
    - p_paramì€ íŒŒë¼ë¯¸í„° ë³€ì´ í™•ë¥ 
    """
    node = node.copy()
    choice = rng.random()
    if choice < 0.33 and node.op != "terminal":
        if node.op in UNARY_OPS:
            newop = rng.choice(DefaultSearchSpace.UNARY_POOL)
            node.op = newop
            node.params = {}
            if newop in ("ts_rank", "sma", "stddev"):
                node.params["window"] = DefaultSearchSpace.random_window(rng)
            if newop in ("delta", "delay"):
                node.params["period"] = DefaultSearchSpace.random_window(rng)
        elif node.op in BINARY_OPS:
            newop = rng.choice(DefaultSearchSpace.BINARY_POOL)
            node.op = newop
            node.params = {}
            if newop == "correlation":
                node.params["window"] = DefaultSearchSpace.random_window(rng)
    elif choice < 0.66:
        if node.op in UNARY_OPS:
            if "window" in node.params and rng.random() < p_param:
                node.params["window"] = DefaultSearchSpace.random_window(rng)
            if "period" in node.params and rng.random() < p_param:
                node.params["period"] = DefaultSearchSpace.random_window(rng)
        if node.op in BINARY_OPS and node.op == "correlation" and rng.random() < p_param:
            node.params["window"] = DefaultSearchSpace.random_window(rng)
    else:
        all_nodes = [n for n in node.iter_nodes() if n.op != "terminal"]
        if all_nodes:
            tgt = rng.choice(all_nodes)
            new_sub = random_tree(rng, max(1, tgt.depth()))
            tgt.op, tgt.left, tgt.right, tgt.params, tgt.terminal_name =                 new_sub.op, new_sub.left, new_sub.right, new_sub.params, new_sub.terminal_name
    return node

def crossover(rng: random.Random, a: Node, b: Node) -> Tuple[Node, Node]:
    """êµì°¨ ì—°ì‚°: ì„ì˜ ë…¸ë“œ ì„ íƒ í›„ êµ¬ì¡°/íŒŒë¼ë¯¸í„° ì„œë¡œ êµí™˜"""
    a = a.copy(); b = b.copy()
    a_nodes = list(a.iter_nodes())
    b_nodes = list(b.iter_nodes())
    a_pick = rng.choice(a_nodes)
    b_pick = rng.choice(b_nodes)
    a_pick.op, b_pick.op = b_pick.op, a_pick.op
    a_pick.left, b_pick.left = b_pick.left, a_pick.left
    a_pick.right, b_pick.right = b_pick.right, a_pick.right
    a_pick.params, b_pick.params = b_pick.params, a_pick.params
    a_pick.terminal_name, b_pick.terminal_name = b_pick.terminal_name, a_pick.terminal_name
    return a, b


@dataclass(eq=False)
class Individual:
    """ê°œì²´ í‘œí˜„: ìˆ˜ì‹ íŠ¸ë¦¬ + ì í•©ë„(ë‹¨ë©´ IC) + PCA ë²¡í„°/íŒ©í„°í–‰ë ¬ ìºì‹œ"""
    tree: Node
    fitness: float = float("nan")
    pca_vec: Optional[np.ndarray] = None
    factor_matrix: Optional[pd.DataFrame] = None
    metrics: Optional[FitnessMetrics] = None
    age: int = 0
    last_improved_gen: Optional[int] = None

class AutoAlphaGA:
    """
    AutoAlpha ìŠ¤íƒ€ì¼ GA êµ¬í˜„ (ê°„ì´ IC ê¸°ë°˜ 1ì°¨ í‰ê°€ + PCA ë‹¤ì–‘ì„±)
    - df_data: Alphasê°€ ê¸°ëŒ€í•˜ëŠ” ì…ë ¥ ë”•ì…”ë„ˆë¦¬
    - hold_horizon: ë¯¸ë˜ ìˆ˜ìµë¥  ê³„ì‚° ì‹œì (h)
    - random_seed: ì¬í˜„ì„±
    """
    def __init__(self,
                 df_data: Dict[str, pd.DataFrame],
                 hold_horizon:int=1,
                 random_seed:int=42,
                 metric_weights: Optional[Dict[str, Any]] = None,
                 age_layer_span:int = 6,
                 stale_age:int = 12):
        self.df_data = df_data
        self.h = int(hold_horizon)
        self.rng = random.Random(random_seed)

        self.ctx = Alphas(df_data)
        self.close_df = self.ctx.close
        self.metric_weights = self._prepare_metric_weights(metric_weights)

        self.eval_horizons = sorted(set([self.h] + list(self.metric_weights["horizons"].keys())))
        self.future_returns_cache: Dict[int, pd.DataFrame] = {
            h: compute_future_returns(self.close_df, h) for h in self.eval_horizons
        }
        self.future_ret = self.future_returns_cache[self.h]
        self.coverage_target = float(self.metric_weights.get("coverage_target", 0.6))
        self.age_layer_span = max(3, int(age_layer_span))
        self.stale_age = max(self.age_layer_span, int(stale_age))

        self.archive: List[Individual] = []
        self.record: List[Individual] = []
        self._generation_counter = 0

    def _prepare_metric_weights(self, metric_weights: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        """
        ì‚¬ìš©ì ì„¤ì •ì„ ê¸°ë³¸ ê°€ì¤‘ì¹˜ì™€ ë³‘í•©í•˜ê³ , ê¸°ê°„ ê°€ì¤‘ì¹˜ë¥¼ ì •ê·œí™”í•©ë‹ˆë‹¤.
        """
        merged: Dict[str, Any] = {
            "horizons": dict(DEFAULT_METRIC_WEIGHTS["horizons"]),
            "ic_ir": DEFAULT_METRIC_WEIGHTS["ic_ir"],
            "novelty": DEFAULT_METRIC_WEIGHTS["novelty"],
            "turnover": DEFAULT_METRIC_WEIGHTS["turnover"],
            "ic_vol": DEFAULT_METRIC_WEIGHTS["ic_vol"],
            "penalty": DEFAULT_METRIC_WEIGHTS["penalty"],
            "coverage_target": DEFAULT_METRIC_WEIGHTS["coverage_target"],
        }

        if metric_weights:
            for key, value in metric_weights.items():
                if key == "horizons" and isinstance(value, dict):
                    for hz, wt in value.items():
                        try:
                            hz_int = int(hz)
                            merged["horizons"][hz_int] = float(wt)
                        except (TypeError, ValueError):
                            continue
                else:
                    merged[key] = value

        # ìŒìˆ˜ ë˜ëŠ” 0 í•©ê³„ ë°©ì§€ë¥¼ ìœ„í•´ ê°€ì¤‘ì¹˜ ì •ê·œí™”
        horizon_total = sum(abs(w) for w in merged["horizons"].values())
        if horizon_total <= 0:
            merged["horizons"] = dict(DEFAULT_METRIC_WEIGHTS["horizons"])
            horizon_total = sum(abs(w) for w in merged["horizons"].values())
        merged["horizons"] = {
            int(h): float(w) / horizon_total for h, w in merged["horizons"].items()
        }
        return merged

    def _compose_score(self, metrics: FitnessMetrics) -> float:
        """
        ê°œë³„ ì§€í‘œë¥¼ ë‹¨ì¼ ìŠ¤ì¹¼ë¼ ì ìˆ˜ë¡œ í•©ì„±í•©ë‹ˆë‹¤.
        """
        horizon_score = 0.0
        for horizon, weight in self.metric_weights["horizons"].items():
            horizon_score += weight * metrics.ic_by_horizon.get(horizon, 0.0)
        metrics.ic_aggregate = horizon_score

        ic_ir_term = self.metric_weights.get("ic_ir", 0.0) * (metrics.ic_ir if np.isfinite(metrics.ic_ir) else 0.0)
        novelty_term = self.metric_weights.get("novelty", 0.0) * (metrics.novelty if np.isfinite(metrics.novelty) else 0.0)
        turnover_term = self.metric_weights.get("turnover", 0.0) * (metrics.turnover if np.isfinite(metrics.turnover) else 0.0)
        ic_vol_term = self.metric_weights.get("ic_vol", 0.0) * (metrics.ic_volatility if np.isfinite(metrics.ic_volatility) else 0.0)
        penalty_term = self.metric_weights.get("penalty", 0.0) * metrics.penalty

        return horizon_score + ic_ir_term + novelty_term - turnover_term - ic_vol_term - penalty_term

    def novelty_score(self, ind: Individual) -> float:
        """
        PCA ê¸°ë°˜ ë‹¤ì–‘ì„± ì ìˆ˜ ê³„ì‚° (AutoAlpha + MAP-Elites ì•„ì´ë””ì–´).
        - archive ë‚´ ìµœê³  ìœ ì‚¬ë„ë¥¼ í™œìš©í•˜ì—¬ 0~1 ë²”ìœ„ì˜ ì‹ ê·œì„± ì¶”ì •
        """
        if ind.factor_matrix is None or ind.factor_matrix.empty:
            return 0.0

        if ind.pca_vec is None:
            try:
                ind.pca_vec = first_pc_vector(ind.factor_matrix)
            except Exception:
                return 0.0

        if not self.archive:
            return 1.0

        similarities: List[float] = []
        for elite in self.archive:
            if elite is ind:
                continue
            if elite.factor_matrix is None:
                continue
            if elite.pca_vec is None and elite.factor_matrix is not None:
                try:
                    elite.pca_vec = first_pc_vector(elite.factor_matrix)
                except Exception:
                    continue
            if elite.pca_vec is None:
                continue
            try:
                sim = float(np.clip(np.dot(ind.pca_vec, elite.pca_vec), -1.0, 1.0))
                similarities.append(sim)
            except Exception:
                continue

        if not similarities:
            return 1.0
        best_sim = max(similarities)
        best_sim = max(-1.0, min(1.0, best_sim))
        if best_sim <= 0:
            return 1.0
        return max(0.0, 1.0 - best_sim)

    def _evaluate_factor_metrics(self, factor_df: pd.DataFrame, ind: Optional[Individual]) -> FitnessMetrics:
        """
        ë©€í‹° ì§€í‘œ ê¸°ë°˜ ì í•©ë„ ê³„ì‚° (ë‹¤ì¤‘ ê¸°ê°„ IC + ì•ˆì •ì„± + ë‹¤ì–‘ì„±).
        """
        ic_by_horizon: Dict[int, float] = {}
        ic_counts: Dict[int, int] = {}
        ic_series_collection: List[pd.Series] = []

        for horizon, _ in self.metric_weights["horizons"].items():
            future_ret = self.future_returns_cache.get(horizon)
            if future_ret is None:
                continue
            ic_series = cross_sectional_ic_series(factor_df, future_ret)
            ic_by_horizon[horizon] = float(ic_series.mean()) if not ic_series.empty else 0.0
            ic_counts[horizon] = int(ic_series.count())
            if not ic_series.empty:
                ic_series_collection.append(ic_series.rename(f"h{horizon}"))

        if ic_series_collection:
            combined_df = pd.concat(ic_series_collection, axis=1)
            combined_series = combined_df.mean(axis=1)
        else:
            combined_series = pd.Series(dtype=float)

        ic_volatility = float(combined_series.std(ddof=0)) if not combined_series.empty else 0.0
        ic_volatility = abs(ic_volatility)

        agg_ic = 0.0
        for horizon, weight in self.metric_weights["horizons"].items():
            agg_ic += weight * ic_by_horizon.get(horizon, 0.0)

        vol_floor = max(float(ic_volatility), 0.02)
        ic_ir = agg_ic / vol_floor
        if not np.isfinite(ic_ir):
            ic_ir = 0.0
        ic_ir = float(np.clip(ic_ir, -10.0, 10.0))

        turnover = compute_factor_turnover(factor_df)
        coverage = 0.0
        if len(factor_df) > 0:
            valid_points = int(combined_series.dropna().shape[0]) if not combined_series.empty else 0
            coverage = valid_points / float(len(factor_df))

        coverage_penalty = max(0.0, self.coverage_target - coverage)
        if not np.isfinite(coverage_penalty):
            coverage_penalty = 0.0

        metrics = FitnessMetrics(
            ic_by_horizon=ic_by_horizon,
            ic_counts=ic_counts,
            ic_aggregate=agg_ic,
            ic_volatility=ic_volatility,
            ic_ir=ic_ir,
            turnover=turnover if np.isfinite(turnover) else 0.0,
            coverage=coverage,
            penalty=coverage_penalty,
        )

        metrics.novelty = self.novelty_score(ind) if ind is not None else 0.0
        metrics.composite = self._compose_score(metrics)
        return metrics

    def _update_archive(self, ind: Individual, diversity_threshold: float) -> None:
        """
        ë‹¤ì–‘ì„±ì´ ì¶©ë¶„í•œ ê°œì²´ë¥¼ ì•„ì¹´ì´ë¸Œì— ì¶”ê°€í•©ë‹ˆë‹¤.
        """
        if ind.factor_matrix is None or ind.factor_matrix.empty:
            return

        novelty = ind.metrics.novelty if ind.metrics else self.novelty_score(ind)
        if ind.metrics:
            ind.metrics.novelty = novelty
            ind.metrics.composite = self._compose_score(ind.metrics)
            ind.fitness = ind.metrics.composite

        diversity_gate = max(0.0, 1.0 - diversity_threshold)
        if novelty < diversity_gate:
            return

        if ind not in self.archive:
            self.archive.append(ind)
        if ind.pca_vec is None:
            try:
                ind.pca_vec = first_pc_vector(ind.factor_matrix)
            except Exception:
                ind.pca_vec = None

    def _tournament_select(self, population: List[Individual], k:int = 3) -> Individual:
        """
        í† ë„ˆë¨¼íŠ¸ ì„ íƒìœ¼ë¡œ ë¶€ëª¨ ì„ íƒ (IC ê¸°ë°˜ ì í•©ë„ ìš°ì„ ).
        """
        if not population:
            raise ValueError("Population is empty")
        size = min(max(1, k), len(population))
        contenders = self.rng.sample(population, size)
        best = max(contenders, key=lambda ind: ind.fitness if np.isfinite(ind.fitness) else -np.inf)
        return best

    def _refresh_stale_population(self,
                                  population: List[Individual],
                                  depth:int,
                                  diversity_threshold:float) -> None:
        """
        ì¼ì • ì„¸ëŒ€ ë™ì•ˆ ê°œì„ ì´ ì—†ëŠ” ê°œì²´(ê³ ë ¹ì¸µ)ë¥¼ ì¬ì‹œì‘í•˜ì—¬ íƒìƒ‰ ë‹¤ì–‘ì„± ë³´ê°•.
        """
        if not population:
            return

        worst_count = max(1, int(len(population) * 0.25))
        start_idx = len(population) - worst_count
        for idx in range(start_idx, len(population)):
            ind = population[idx]
            if ind.age < self.stale_age:
                continue
            new_tree = random_tree(self.rng, depth)
            new_ind = Individual(tree=new_tree)
            self.evaluate(new_ind)
            new_ind.age = 0
            new_ind.last_improved_gen = self._generation_counter
            population[idx] = new_ind
            self._update_archive(new_ind, diversity_threshold)

    def evaluate(self, ind: Individual) -> float:
        """
        ê°œì²´ ì í•©ë„ í‰ê°€
        - ìˆ˜ì‹ íŠ¸ë¦¬ë¥¼ ì‹¤í–‰í•˜ì—¬ íŒ©í„° í–‰ë ¬ ê³„ì‚°
        - ë¯¸ë˜ ìˆ˜ìµë¥ ê³¼ ì¼ìë³„ ë‹¨ë©´ ìƒê´€(IC) í‰ê· ì„ ì í•©ë„ë¡œ ì‚¬ìš©
        - ê³„ì‚° ì•ˆì „ì„± ìœ„í•´ inf/NaN â†’ 0 ì²˜ë¦¬
        """
        # í‰ê°€ íšŸìˆ˜ ì¶”ì  (ë„ˆë¬´ ë§ì´ ì¶œë ¥í•˜ì§€ ì•Šë„ë¡ ê°„í—ì ìœ¼ë¡œë§Œ)
        if not hasattr(self, '_eval_counter'):
            self._eval_counter = 0
        self._eval_counter += 1
        
        # ê°œì²´ê°€ ë„ˆë¬´ ë³µì¡í•˜ë©´ ìŠ¤í‚µ (ë¬´í•œë£¨í”„ ë°©ì§€)
        if ind.tree.depth() > 10:
            ind.fitness = 0.0
            return 0.0
            
        try:
            f = ind.tree.compile()
            val = f(self.ctx)

            # ê²°ê³¼ í˜•íƒœ ì •ê·œí™”
            if isinstance(val, pd.Series):
                try:
                    if isinstance(val.index, pd.MultiIndex):
                        factor_df = val.unstack()
                    else:
                        if len(val) == len(self.close_df):
                            factor_df = pd.DataFrame(
                                np.tile(val.values.reshape(-1, 1), (1, self.close_df.shape[1])),
                                index=self.close_df.index,
                                columns=self.close_df.columns
                            )
                        else:
                            factor_df = self.close_df * 0.0
                except Exception:
                    factor_df = self.close_df * 0.0
            elif isinstance(val, pd.DataFrame):
                factor_df = val
            else:
                factor_df = self.close_df * 0.0

            factor_df = factor_df.replace([np.inf, -np.inf], 0).fillna(0)

            if factor_df.shape != self.close_df.shape:
                factor_df = factor_df.reindex(
                    index=self.close_df.index,
                    columns=self.close_df.columns,
                    fill_value=0
                )

            ind.factor_matrix = factor_df
            metrics = self._evaluate_factor_metrics(factor_df, ind)
            ind.metrics = metrics
            ind.fitness = float(metrics.composite) if np.isfinite(metrics.composite) else 0.0
            return ind.fitness

        except Exception as e:
            if self._eval_counter % 100 == 1:
                print(f"               âš ï¸ í‰ê°€ ì—ëŸ¬ (#{self._eval_counter}): {str(e)[:50]}...")
            ind.fitness = 0.0
            ind.factor_matrix = self.close_df * 0.0
            ind.metrics = FitnessMetrics()
            ind.metrics.composite = 0.0
            ind.metrics.ic_aggregate = 0.0
            return 0.0

    def pca_sim_to_archive(self, ind: Individual, threshold: float = 0.9) -> float:
        """
        ì•„ì¹´ì´ë¸Œ ë‚´ ê°œì²´ë“¤ê³¼ 1ì£¼ì„±ë¶„ ë²¡í„° ìœ ì‚¬ë„ ìµœëŒ€ê°’ì„ ë°˜í™˜
        - threshold ë¯¸ë§Œì´ë©´ ì¶©ë¶„íˆ ë‹¤ì–‘í•˜ë‹¤ê³  íŒë‹¨
        """
        if ind.factor_matrix is None:
            return 0.0
        if ind.pca_vec is None:
            ind.pca_vec = first_pc_vector(ind.factor_matrix)
        sims = []
        for e in self.archive:
            if e.pca_vec is None and e.factor_matrix is not None:
                e.pca_vec = first_pc_vector(e.factor_matrix)
            if e.pca_vec is not None:
                sims.append(float(np.corrcoef(ind.pca_vec, e.pca_vec)[0,1]))
        return max(sims) if sims else 0.0

    def init_population(self,
                        size:int,
                        depth:int,
                        warmstart_k:int=4,
                        diversity_threshold:float=0.9) -> List[Individual]:
        """
        ì´ˆê¸° ê°œì²´êµ° ìƒì„±(ì›Œë°ìŠ¤íƒ€íŠ¸): ë£¨íŠ¸ í…œí”Œë¦¿ ê¸°ë°˜ í›„ë³´ Kë°° ìƒì„± í›„ ìƒìœ„ 1/K ì„ íƒ
        """
        cand: List[Individual] = []
        roots = DefaultSearchSpace.ROOT_TEMPLATES
        while len(cand) < size*warmstart_k:
            root = random.choice(roots).copy()
            while root.depth() < depth:
                if self.rng.random() < 0.5:
                    root = random_unary(self.rng, root)
                else:
                    root = random_binary(self.rng, root, random_terminal(self.rng))
            cand.append(Individual(tree=root))

        while len(cand) < size*warmstart_k:
            cand.append(Individual(tree=random_tree(self.rng, depth)))

        print(f"            ğŸ§® ê°œì²´ í‰ê°€ ì¤‘: {len(cand)}ê°œ í›„ë³´...")
        import time
        start_time = time.time()
        diversity_gate = max(0.0, 1.0 - diversity_threshold)

        for i, ind in enumerate(cand, 1):
            ind_start = time.time()
            self.evaluate(ind)
            ind.age = 0
            ind.last_improved_gen = 0
            if ind.metrics is None:
                ind.metrics = FitnessMetrics()
                ind.metrics.composite = ind.fitness
            novelty = ind.metrics.novelty if ind.metrics and np.isfinite(ind.metrics.novelty) else self.novelty_score(ind)
            if ind.metrics:
                ind.metrics.novelty = novelty
                ind.metrics.composite = self._compose_score(ind.metrics)
                ind.fitness = ind.metrics.composite
            ind_time = time.time() - ind_start

            if i % 10 == 0 or i == len(cand):
                elapsed = time.time() - start_time
                avg_time = elapsed / i
                remaining = (len(cand) - i) * avg_time
                print(f"               [{i:3d}/{len(cand)}] í‰ê°€ ì™„ë£Œ (ê°œì²´ë‹¹ {ind_time:.2f}ì´ˆ, ì˜ˆìƒ ì”ì—¬ {remaining:.1f}ì´ˆ)...")
            if novelty >= diversity_gate:
                self.archive.append(ind)
                if ind.pca_vec is None and ind.factor_matrix is not None:
                    try:
                        ind.pca_vec = first_pc_vector(ind.factor_matrix)
                    except Exception:
                        ind.pca_vec = None

        print(f"            ğŸ“Š í‰ê°€ ì™„ë£Œ, ìƒìœ„ ì„ ë³„ ì¤‘...")
        cand.sort(key=lambda x: (-(x.fitness if np.isfinite(x.fitness) else -np.inf)))
        selected = cand[:max(1, len(cand)//warmstart_k)]
        return selected

    def evolve_one_depth(self,
                         depth:int,
                         population:int,
                         generations:int,
                         warmstart_k:int=4,
                         n_keep:int=25,
                         p_mutation:float=0.3,
                         p_crossover:float=0.7,
                         diversity_threshold:float=0.9) -> List[Individual]:
        """
        ê³ ì • ê¹Šì´ì—ì„œì˜ ì§„í™” ë£¨í”„
        - ë¶€ëª¨-ìì‹ ì¹˜í™˜, ë‹¤ì–‘ì„±(1ì£¼ì„±ë¶„ ìœ ì‚¬ë„) í•„í„°, ì—˜ë¦¬íŠ¸ ë³´ê´€
        """
        print(f"         ğŸŒ± ê°œì²´êµ° ì´ˆê¸°í™” ì¤‘ (í¬ê¸°={population})...")
        pop = self.init_population(population, depth, warmstart_k=warmstart_k, diversity_threshold=diversity_threshold)
        pop.sort(key=lambda x: (-(x.fitness if np.isfinite(x.fitness) else -np.inf)))

        valid_pop = [ind for ind in pop if np.isfinite(ind.fitness)]
        if valid_pop:
            leader = valid_pop[0]
            avg_init = np.mean([ind.fitness for ind in valid_pop])
            leader_metrics = leader.metrics.ic_by_horizon if leader.metrics else {}
            horizon_snapshot = ", ".join(
                [f"h{hz}:{leader_metrics.get(hz, 0.0):.3f}" for hz in sorted(self.metric_weights["horizons"].keys())]
            )
            print(f"         ğŸ“Š ì´ˆê¸° ê°œì²´êµ°: {len(valid_pop)}/{population}ê°œ ìœ íš¨, ìµœê³ ={leader.fitness:.4f}, í‰ê· ={avg_init:.4f}")
            if horizon_snapshot:
                print(f"            â†³ ê¸°ê°„ë³„ IC: {horizon_snapshot}")
        else:
            print(f"         âš ï¸ ì´ˆê¸° ê°œì²´êµ°: ìœ íš¨í•œ ê°œì²´ ì—†ìŒ")

        for ind in pop:
            self._update_archive(ind, diversity_threshold)

        print(f"         ğŸ”„ ì§„í™” ì‹œì‘ ({generations}ì„¸ëŒ€)...")
        for gen in range(generations):
            self._generation_counter += 1
            for ind in pop:
                ind.age += 1

            if gen % 5 == 0 or gen == generations - 1:
                valid_current = [ind for ind in pop if np.isfinite(ind.fitness)]
                if valid_current:
                    leader = valid_current[0]
                    avg_current = np.mean([ind.fitness for ind in valid_current])
                    metrics = leader.metrics
                    turnover_val = metrics.turnover if metrics else 0.0
                    coverage_val = metrics.coverage if metrics else 0.0
                    print(f"            ğŸ§¬ ì„¸ëŒ€ {gen+1:3d}/{generations}: ìµœê³ ={leader.fitness:.4f}, í‰ê· ={avg_current:.4f}, íšŒì „={turnover_val:.3f}, ì»¤ë²„ë¦¬ì§€={coverage_val:.2f}")
                else:
                    print(f"            ğŸ§¬ ì„¸ëŒ€ {gen+1:3d}/{generations}: ìœ íš¨í•œ ê°œì²´ ì—†ìŒ")

            if len(pop) < 2:
                sole = pop[0]
                child_tree = mutate(self.rng, sole.tree)
                child_ind = Individual(tree=child_tree)
                self.evaluate(child_ind)
                child_ind.age = 0
                child_ind.last_improved_gen = self._generation_counter
                self._update_archive(child_ind, diversity_threshold)
                if child_ind.fitness > sole.fitness:
                    pop[0] = child_ind
                continue

            p1 = self._tournament_select(pop, k=3)
            p2 = self._tournament_select(pop, k=3)
            if p1 is p2 and len(pop) > 2:
                for _ in range(3):
                    candidate = self._tournament_select(pop, k=4)
                    if candidate is not p1:
                        p2 = candidate
                        break

            children: List[Individual] = []
            if self.rng.random() < p_crossover:
                c1_tree, c2_tree = crossover(self.rng, p1.tree, p2.tree)
                children.extend([Individual(tree=c1_tree), Individual(tree=c2_tree)])
            if self.rng.random() < p_mutation:
                children.append(Individual(tree=mutate(self.rng, p1.tree)))
                if len(pop) > 1:
                    children.append(Individual(tree=mutate(self.rng, p2.tree)))
            if not children:
                children.append(Individual(tree=mutate(self.rng, p1.tree)))

            prev_best = pop[0].fitness if pop else -np.inf

            for child in children:
                self.evaluate(child)
                child.age = 0
                child.last_improved_gen = self._generation_counter
                self._update_archive(child, diversity_threshold)

            pop.extend(children)
            pop.sort(key=lambda x: (-(x.fitness if np.isfinite(x.fitness) else -np.inf)))
            pop = pop[:population]

            if pop and pop[0].fitness > prev_best + 1e-6:
                pop[0].last_improved_gen = self._generation_counter

            if (gen + 1) % self.age_layer_span == 0:
                self._refresh_stale_population(pop, depth, diversity_threshold)
                pop.sort(key=lambda x: (-(x.fitness if np.isfinite(x.fitness) else -np.inf)))

        pop.sort(key=lambda x: (-(x.fitness if np.isfinite(x.fitness) else -np.inf)))
        elites: List[Individual] = []
        diversity_gate = max(0.0, 1.0 - diversity_threshold)
        for ind in pop:
            if len(elites) >= n_keep:
                break
            novelty = ind.metrics.novelty if ind.metrics else self.novelty_score(ind)
            if novelty >= diversity_gate or not elites:
                elites.append(ind)
        return elites

    def run(self,
            max_depth:int=3,
            population:int=60,
            generations:int=20,
            warmstart_k:int=4,
            n_keep_per_depth:int=25,
            p_mutation:float=0.3,
            p_crossover:float=0.7,
            diversity_threshold:float=0.9) -> List[Individual]:
        """
        ê¹Šì´ë¥¼ 1â†’max_depthê¹Œì§€ í™•ì¥í•˜ë©° ìˆœì°¨ íƒìƒ‰ í›„, ì „ì²´ ì—˜ë¦¬íŠ¸ ì •ë ¬ ë°˜í™˜
        """
        print(f"      ğŸ—ï¸ ê³„ì¸µì  íƒìƒ‰ ì‹œì‘ (ê¹Šì´ 1â†’{max_depth})")
        all_elites: List[Individual] = []
        
        for depth in range(1, max_depth+1):
            print(f"      ğŸ“ [ê¹Šì´ {depth}/{max_depth}] ì§„í™” ì‹œì‘...")
            elites = self.evolve_one_depth(
                depth=depth,
                population=population,
                generations=generations,
                warmstart_k=warmstart_k,
                n_keep=n_keep_per_depth,
                p_mutation=p_mutation,
                p_crossover=p_crossover,
                diversity_threshold=diversity_threshold,
            )
            all_elites.extend(elites)
            
            # í•´ë‹¹ ê¹Šì´ ê²°ê³¼ ìš”ì•½
            valid_elites = [e for e in elites if np.isfinite(e.fitness)]
            if valid_elites:
                valid_elites.sort(key=lambda x: (-(x.fitness if np.isfinite(x.fitness) else -np.inf)))
                leader = valid_elites[0]
                best_score = leader.fitness
                avg_score = np.mean([e.fitness for e in valid_elites])
                leader_metrics = leader.metrics
                turnover_val = leader_metrics.turnover if leader_metrics else 0.0
                horizon_snapshot = ""
                if leader_metrics:
                    horizon_snapshot = ", ".join(
                        [f"h{hz}:{leader_metrics.ic_by_horizon.get(hz, 0.0):.3f}" for hz in sorted(self.metric_weights["horizons"].keys())]
                    )
                print(f"         âœ… ì™„ë£Œ: {len(valid_elites)}ê°œ ì—˜ë¦¬íŠ¸, ìµœê³ ì ={best_score:.4f}, í‰ê· ì ìˆ˜={avg_score:.4f}, íšŒì „={turnover_val:.3f}")
                if horizon_snapshot:
                    print(f"            â†³ ê¸°ê°„ë³„ IC: {horizon_snapshot}")
            else:
                print(f"         âš ï¸ ì™„ë£Œ: ìœ íš¨í•œ ì—˜ë¦¬íŠ¸ ì—†ìŒ")
        
        all_elites.sort(key=lambda x: (-(x.fitness if np.isfinite(x.fitness) else -np.inf)))
        valid_total = len([e for e in all_elites if np.isfinite(e.fitness)])
        print(f"      ğŸ¯ ê³„ì¸µì  íƒìƒ‰ ì™„ë£Œ: ì´ {valid_total}ê°œ ìœ íš¨ ì—˜ë¦¬íŠ¸")
        
        return all_elites


HEADER = '''# -*- coding: utf-8 -*-
"""
ìë™ ìƒì„±ëœ ì•ŒíŒŒ ëª¨ìŒ (GA ê²°ê³¼)
- íŒŒì¼ ìƒì„±ì‹œê°: {ts}
- ì°¸ê³ : autoalpha_ga.write_new_alphas_file()ê°€ ìƒì„±
ì£¼ì˜: ìˆ˜ë™ ìˆ˜ì • ì‹œ ì¬ìƒì„± ì‹œ ë®ì–´ì”Œì›Œì§‘ë‹ˆë‹¤.
"""

import pandas as pd
import numpy as np
from Alphas import (
    Alphas,
    ts_sum, sma, stddev, correlation, covariance,
    ts_rank, product, ts_min, ts_max, delta, delay, rank, scale,
    ts_argmax, ts_argmin, decay_linear,
    safe_clean, adv, floor_window
)

# min/max ì—°ì‚°ì„ ìœ„í•œ numpy import í™•ì‹¤íˆ í•˜ê¸°
import numpy as np

class NewAlphas(Alphas):
    """
    GAë¡œ ë°œêµ´ëœ ì•ŒíŒŒ íŒ©í„° ëª¨ìŒ.
    ê° ë©”ì„œë“œëŠ” pandas Series(ë˜ëŠ” DataFrameì˜ ì—´ ì‹œë¦¬ì¦ˆ)ë¥¼ ë°˜í™˜í•´ì•¼ í•©ë‹ˆë‹¤.
    """
'''

def write_new_alphas_file(elites: List[Individual], out_path: Optional[str] = None):
    """
    ìƒìœ„ ê°œì²´ë“¤ì„ `backend_module/NewAlphas.py`ë¡œ ì§ë ¬í™”í•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤.
    - out_pathë¥¼ ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ ì´ íŒŒì¼ ê¸°ì¤€ ìƒëŒ€ê²½ë¡œë¡œ backend_module/NewAlphas.pyì— ê¸°ë¡í•©ë‹ˆë‹¤.
    - ê¸°ì¡´ íŒŒì¼ì€ ë®ì–´ì”Œì›Œì§‘ë‹ˆë‹¤.
    """
    if out_path is None:
        # í´ë” ì¡´ì¬ í™•ì¸ ë° ìƒì„±
        os.makedirs(BACKEND_MODULE_DIR, exist_ok=True)
        out_path = os.path.join(BACKEND_MODULE_DIR, "NewAlphas.py")

    lines = [HEADER.format(ts=pd.Timestamp.utcnow().strftime("%Y-%m-%d %H:%M:%S UTC"))]
    for i, ind in enumerate(elites, start=1):
        name = f"alphaGA{i:03d}"
        expr = ind.tree.to_python_expr()
        body = f"        out = ({expr})\n        return out.replace([np.inf, -np.inf], 0).fillna(0)\n"
        func = f"    def {name}(self):\n{body}\n"
        lines.append(func)

    with open(out_path, "w", encoding="utf-8") as f:
        f.write("\n".join(lines))
    return out_path


if __name__ == "__main__":
    msg = (
        "[AutoAlpha GA]\n"
        "- ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ í˜•íƒœì…ë‹ˆë‹¤.\n"
        "- ì‹¤ì œ ì‹¤í–‰ ì‹œì—ëŠ” ì‚¬ìš©ì ë°ì´í„°(df_data)ë¥¼ êµ¬ì„±í•˜ì—¬ AutoAlphaGA(df_data)ë¡œ ìƒì„±í•˜ì„¸ìš”.\n"
        "- run() í˜¸ì¶œ í›„ write_new_alphas_file()ë¡œ NewAlphas.pyë¥¼ ìƒì„±í•˜ì„¸ìš”.\n"
    )
    print(msg)
