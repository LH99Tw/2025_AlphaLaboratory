
# -*- coding: utf-8 -*-
"""
AutoAlpha-style Evolutionary Search (GA) for Formulaic Alphas
================================================================
ë³¸ ëª¨ë“ˆì€ ë‹¤ìŒ ë…¼ë¬¸ì˜ ì•„ì´ë””ì–´(ê³„ì¸µì  íƒìƒ‰ + PCA-QD + Warm Start + Parent-Offspring Replacement)ë¥¼
ì‹¤ë¬´ ì½”ë“œë¡œ ì˜®ê¸´ MVP êµ¬í˜„ì…ë‹ˆë‹¤.

    AutoAlpha: an Efficient Hierarchical Evolutionary Algorithm for Mining Alpha Factors
    (Zhang et al., IJCAI 2020, arXiv:2002.08245)

ë³¸ êµ¬í˜„ì€ ë‹¤ìŒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.
- Alphas.pyì˜ ì—°ì‚°ì/ì…ë ¥(OHLCV, VWAP, returns ë“±)ì„ ì¬ì‚¬ìš©í•˜ì—¬ "ìˆ˜ì‹ íŠ¸ë¦¬" í˜•íƒœì˜ ì•ŒíŒŒë¥¼ ì§„í™”ì‹œí‚µë‹ˆë‹¤.
- 1ì°¨ í‰ê°€ëŠ” ë¹ ë¥¸ IC(Information Coefficient) ê¸°ë°˜ì´ë©°, ìƒìœ„ í›„ë³´ë§Œ ë³„ë„ ë°±í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ(ì˜ˆ: 5_results.LongOnlyBacktestSystem)ì— ë„˜ê¸¸ ìˆ˜ ìˆë„ë¡ í›…ì„ ì œê³µí•©ë‹ˆë‹¤.
- ìµœì¢… ì„ ë³„ëœ ì•ŒíŒŒë¥¼ NewAlphas.pyì— í•¨ìˆ˜(alphaGA001, ...) í˜•íƒœë¡œ ìë™ ê¸°ë¡í•©ë‹ˆë‹¤.

ìš”êµ¬ë˜ëŠ” ë°ì´í„° í˜•ì‹ (ì¤‘ìš”):
- Alphas.Alphas ê°€ ê¸°ëŒ€í•˜ëŠ” ë™ì¼í•œ df_data êµ¬ì¡°ë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
  ì¦‰, ë”•ì…”ë„ˆë¦¬ ë˜ëŠ” ë„¤ì„ë“œ ê°ì²´ë¡œ ë‹¤ìŒ í‚¤ë¥¼ ê°€ì§„ pandas.DataFrame(ì¸ë±ìŠ¤: Date, ì»¬ëŸ¼: Ticker)ë“¤ì„ ì œê³µí•©ë‹ˆë‹¤.
    'S_DQ_OPEN', 'S_DQ_HIGH', 'S_DQ_LOW', 'S_DQ_CLOSE', 'S_DQ_VOLUME', 'S_DQ_PCTCHANGE', 'S_DQ_AMOUNT'
- ê° DataFrameì˜ shapeì€ (ì‹œê°„ x ì¢…ëª©) ì´ì–´ì•¼ í•˜ë©°, ì¸ë±ìŠ¤ëŠ” ì •ë ¬ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.

ë¹ ë¥¸ ì‹œì‘:
---------
from autoalpha_ga import AutoAlphaGA, DefaultSearchSpace, write_new_alphas_file
from Alphas import Alphas

# df_dataë¥¼ ì¤€ë¹„ (ì‚¬ìš©ì ë¡œë”ë¡œ ìƒì„±)
ga = AutoAlphaGA(df_data, hold_horizon=1, random_seed=42)

elites = ga.run(
    max_depth=3,
    population=60,
    generations=20,
    warmstart_k=4,          # Kë°° ìƒì„± í›„ ìƒìœ„ 1/Kë§Œ ì´ˆê¸° ê°œì²´êµ°ì— í¸ì…
    n_keep_per_depth=25,    # ê° depthì˜ ì—˜ë¦¬íŠ¸ ë³´ê´€ ìƒí•œ
    p_mutation=0.3,
    p_crossover=0.7,
)

# ìƒìœ„ Mê°œë¥¼ NewAlphas.pyë¡œ ê¸°ë¡
write_new_alphas_file(elites[:10], out_path="NewAlphas.py")

í†µí•© íŒ:
--------
- 5_results.LongOnlyBacktestSystem ê³¼ ì—°ë™í•˜ë ¤ë©´, write_new_alphas_file()ë¡œ NewAlphas.py ìƒì„± í›„
  ê¸°ì¡´ íŒŒì´í”„ë¼ì¸ì—ì„œ alpha íŒŒì¼ ìƒì„± ë‹¨ê³„ì— NewAlphas.NewAlphasì˜ ë©”ì„œë“œë“¤ì„ í˜¸ì¶œí•´ ê³„ì‚° ê²°ê³¼ë¥¼ CSVë¡œ ë‚´ë¦¬ë©´ ë©ë‹ˆë‹¤.
"""

from __future__ import annotations

import math
import random
import json
import dataclasses
from dataclasses import dataclass, field
from typing import Any, Callable, Dict, List, Optional, Tuple, Union

import os
import sys
import numpy as np
import pandas as pd

# ==========================================
# ê²½ë¡œ ì„¤ì •: ì´ íŒŒì¼ ê¸°ì¤€ ìƒëŒ€ê²½ë¡œë¡œ backend_module ì¶”ê°€
# - ì–´ë””ì„œ ì‹¤í–‰í•˜ë“  backend_module/Alphas.py ë¥¼ import ê°€ëŠ¥í•˜ê²Œ í•¨
# ==========================================
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(CURRENT_DIR)
BACKEND_MODULE_DIR = os.path.join(PROJECT_ROOT, 'backend_module')

# ê²½ë¡œ ì¡´ì¬ í™•ì¸ ë° ì¹œì ˆí•œ ì—ëŸ¬ ë©”ì‹œì§€
if not os.path.exists(BACKEND_MODULE_DIR):
    raise ImportError(f"backend_module ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {BACKEND_MODULE_DIR}\n"
                     f"í”„ë¡œì íŠ¸ êµ¬ì¡°ë¥¼ í™•ì¸í•˜ê±°ë‚˜ PYTHONPATHë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")

if BACKEND_MODULE_DIR not in sys.path:
    sys.path.insert(0, BACKEND_MODULE_DIR)

# Alphas.pyì˜ ì—°ì‚°ì/ì…ë ¥ê³¼ ë™ì¼ í™˜ê²½ì—ì„œ ê³„ì‚°í•˜ê¸° ìœ„í•´ import (backend_module ë‚´ ìœ„ì¹˜)
from Alphas import (
    Alphas,
    ts_sum, sma, stddev, correlation, covariance,
    ts_rank, product, ts_min, ts_max, delta, delay, rank, scale,
    ts_argmax, ts_argmin, decay_linear,
    safe_clean, adv, floor_window
)


# ===============================
# í‘œí˜„: ìˆ˜ì‹ íŠ¸ë¦¬ (Expression Tree)
# ===============================

# ì—°ì‚°ì ë©”íƒ€ ì •ì˜
UNARY_OPS = {
    "rank": {"fn": rank, "params": []},
    "ts_rank": {"fn": ts_rank, "params": ["window"]},
    "delta": {"fn": delta, "params": ["period"]},
    "delay": {"fn": delay, "params": ["period"]},
    "sma": {"fn": sma, "params": ["window"]},
    "stddev": {"fn": stddev, "params": ["window"]},
    "ts_max": {"fn": ts_max, "params": ["window"]},
    "ts_min": {"fn": ts_min, "params": ["window"]},
    "ts_argmax": {"fn": ts_argmax, "params": ["window"]},
    "ts_argmin": {"fn": ts_argmin, "params": ["window"]},
    "decay_linear": {"fn": decay_linear, "params": ["period"], "frame_only": True},
}

BINARY_OPS = {
    "add": {"symbol": "+", "fn": lambda a, b: a + b},
    "sub": {"symbol": "-", "fn": lambda a, b: a - b},
    "mul": {"symbol": "*", "fn": lambda a, b: a * b},
    "div": {"symbol": "/", "fn": lambda a, b: (a / (b.replace(0, np.nan) if hasattr(b, 'replace') else b)).replace([np.inf, -np.inf], np.nan)},
    "min": {"symbol": "min", "fn": lambda a, b: pd.DataFrame(np.minimum(a.values, b.values), index=a.index, columns=a.columns) if hasattr(a, 'index') and hasattr(b, 'index') else np.minimum(a, b)},
    "max": {"symbol": "max", "fn": lambda a, b: pd.DataFrame(np.maximum(a.values, b.values), index=a.index, columns=a.columns) if hasattr(a, 'index') and hasattr(b, 'index') else np.maximum(a, b)},
    "correlation": {"symbol": "correlation", "fn": correlation, "params": ["window"]},
}

TERMINALS = ["open", "high", "low", "close", "volume", "vwap", "returns"]


@dataclass
class Node:
    op: str
    left: Optional['Node'] = None
    right: Optional['Node'] = None
    params: Dict[str, Any] = field(default_factory=dict)
    terminal_name: Optional[str] = None

    def depth(self) -> int:
        if self.op == "terminal":
            return 1
        dl = self.left.depth() if self.left else 0
        dr = self.right.depth() if self.right else 0
        return 1 + max(dl, dr)

    def copy(self) -> 'Node':
        return Node(
            op=self.op,
            left=self.left.copy() if self.left else None,
            right=self.right.copy() if self.right else None,
            params=dict(self.params),
            terminal_name=self.terminal_name
        )

    def compile(self) -> Callable[[Alphas], pd.Series]:
        """
        ìˆ˜ì‹ íŠ¸ë¦¬ë¥¼ ì‹¤í–‰ ê°€ëŠ¥í•œ í•¨ìˆ˜ë¡œ ì»´íŒŒì¼í•©ë‹ˆë‹¤.
        - ë°˜í™˜ í•¨ìˆ˜ëŠ” Alphas ì»¨í…ìŠ¤íŠ¸(ê°€ê²©/ê±°ë˜ëŸ‰ ë“±)ë¥¼ ë°›ì•„ íŒ©í„° ì‹œê³„ì—´(Series ë˜ëŠ” DataFrame)ì„ ì¶œë ¥í•©ë‹ˆë‹¤.
        - ê³„ì‚° ê²°ê³¼ì˜ inf/NaNì€ 0ìœ¼ë¡œ ì •ë¦¬í•˜ì—¬ ì•ˆì •ì„± í™•ë³´.
        """
        def _compile(node: 'Node') -> Callable[[Alphas], pd.Series]:
            if node.op == "terminal":
                name = node.terminal_name
                def f(ctx: Alphas):
                    return getattr(ctx, name)
                return f

            if node.op in UNARY_OPS:
                fn_meta = UNARY_OPS[node.op]
                child_f = _compile(node.left)
                def f(ctx: Alphas):
                    x = child_f(ctx)
                    if fn_meta.get("frame_only"):
                        return fn_meta["fn"](x.to_frame(), **node.params).iloc[:, 0]
                    return fn_meta["fn"](x, **node.params)
                return f

            if node.op in BINARY_OPS:
                fn_meta = BINARY_OPS[node.op]
                left_f = _compile(node.left)
                right_f = _compile(node.right)
                if node.op == "correlation":
                    w = int(node.params.get("window", 10))
                    def f(ctx: Alphas):
                        a = left_f(ctx); b = right_f(ctx)
                        # correlation í˜•ìƒ ê²€ì¦: ë™ì¼í•œ shapeì˜ DataFrame/Seriesë§Œ í—ˆìš©
                        if hasattr(a, 'shape') and hasattr(b, 'shape'):
                            if a.shape != b.shape:
                                # í˜•ìƒì´ ë‹¤ë¥´ë©´ 0 í–‰ë ¬ ë°˜í™˜
                                return pd.DataFrame(0, index=a.index if hasattr(a, 'index') else range(len(a)), 
                                                  columns=a.columns if hasattr(a, 'columns') else [0])
                        try:
                            result = fn_meta["fn"](a, b, w)
                            # correlation ê²°ê³¼ ì•ˆì „ì„± í™•ë³´
                            if hasattr(result, 'replace'):
                                result = result.replace([np.inf, -np.inf], 0).fillna(0)
                            return result
                        except:
                            # correlation ê³„ì‚° ì‹¤íŒ¨ ì‹œ 0 í–‰ë ¬ ë°˜í™˜
                            return pd.DataFrame(0, index=a.index if hasattr(a, 'index') else range(len(a)), 
                                              columns=a.columns if hasattr(a, 'columns') else [0])
                    return f

                def f(ctx: Alphas):
                    a = left_f(ctx); b = right_f(ctx)
                    return fn_meta["fn"](a, b)
                return f

            raise ValueError(f"Unknown op: {node.op}")

        f = _compile(self)

        def safe(ctx: Alphas) -> pd.Series:
            out = f(ctx)
            if isinstance(out, (pd.DataFrame, pd.Series)):
                out = out.replace([np.inf, -np.inf], 0).fillna(0)
            return out
        return safe

    def to_python_expr(self) -> str:
        """
        í˜„ì¬ ìˆ˜ì‹ íŠ¸ë¦¬ë¥¼ Python í‘œí˜„ì‹ ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        - ìƒì„±ëœ ë¬¸ìì—´ì€ NewAlphas.py ë‚´ ê°œë³„ ë©”ì„œë“œ ë³¸ë¬¸ì—ì„œ ê·¸ëŒ€ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.
        - ì¼ë¶€ ì—°ì‚°ì(ì˜ˆ: decay_linear, correlation)ëŠ” í”„ë ˆì„/ìœˆë„ìš° ì¸ìë¥¼ ë§ì¶° ì²˜ë¦¬í•©ë‹ˆë‹¤.
        """
        if self.op == "terminal":
            return f"self.{self.terminal_name}"

        if self.op in UNARY_OPS:
            child = self.left.to_python_expr()
            if self.op in ("ts_rank", "sma", "stddev", "ts_max", "ts_min", "ts_argmax", "ts_argmin"):
                w = int(self.params.get("window") or self.params.get("period", 10))
                return f"{self.op}({child}, {w})"
            if self.op in ("delta", "delay"):
                p = int(self.params.get("period", 1))
                return f"{self.op}({child}, {p})"
            if self.op == "rank":
                return f"rank({child})"
            if self.op == "decay_linear":
                p = int(self.params.get('period', 10))
                return f"decay_linear({child}.to_frame(), {p}).iloc[:, 0]"
            return f"{self.op}({child})"

        if self.op in BINARY_OPS:
            left = self.left.to_python_expr()
            right = self.right.to_python_expr()
            if self.op == "correlation":
                w = int(self.params.get("window", 10))
                return f"correlation({left}, {right}, {w})"
            sym = BINARY_OPS[self.op]["symbol"]
            if sym in {"+", "-", "*", "/"}:
                return f"({left} {sym} {right})"
            if sym == "min":
                return f"pd.DataFrame(np.minimum(({left}).values, ({right}).values), index=({left}).index, columns=({left}).columns)"
            if sym == "max":
                return f"pd.DataFrame(np.maximum(({left}).values, ({right}).values), index=({left}).index, columns=({left}).columns)"
        raise ValueError(f"Unknown op {self.op}")

    def iter_nodes(self):
        yield self
        if self.left: 
            yield from self.left.iter_nodes()
        if self.right:
            yield from self.right.iter_nodes()


class DefaultSearchSpace:
    """
    íƒìƒ‰ ê³µê°„ ì •ì˜ í´ë˜ìŠ¤
    - ì´ˆê¸° ë£¨íŠ¸ í…œí”Œë¦¿, ì‚¬ìš© ê°€ëŠ¥í•œ ë‹¨í•­/ì´í•­ ì—°ì‚°ì, ìœˆë„ìš° í›„ë³´ ë“±ì„ ë³´ìœ í•©ë‹ˆë‹¤.
    - ê²€ìƒ‰ ë‚œì´ë„/ë‹¤ì–‘ì„±ì„ ì¡°ì ˆí•˜ë ¤ë©´ í’€ ë˜ëŠ” ìœˆë„ìš° ë¶„í¬ë¥¼ ìˆ˜ì •í•˜ì„¸ìš”.
    """
    WINDOW_CANDIDATES = [3,5,10,20,30,60,120]
    ROOT_TEMPLATES: List[Node] = [
        Node(op="terminal", terminal_name="vwap"),
        Node(op="terminal", terminal_name="close"),
        Node(op="terminal", terminal_name="open"),
        Node(op="terminal", terminal_name="high"),
        Node(op="terminal", terminal_name="low"),
        Node(op="terminal", terminal_name="volume"),
        Node(op="div", left=Node(op="terminal", terminal_name="vwap"), right=Node(op="terminal", terminal_name="close")),
        Node(op="sub", left=Node(op="terminal", terminal_name="close"), right=Node(op="terminal", terminal_name="open")),
        Node(op="sub", left=Node(op="terminal", terminal_name="high"),  right=Node(op="terminal", terminal_name="low")),
    ]

    UNARY_POOL = ["rank", "ts_rank", "delta", "delay", "sma", "stddev"]
    BINARY_POOL = ["add", "sub", "mul", "div", "min", "max", "correlation"]

    @classmethod
    def random_window(cls, rng: random.Random) -> int:
        return int(rng.choice(cls.WINDOW_CANDIDATES))


def compute_future_returns(close_df: pd.DataFrame, h: int) -> pd.DataFrame:
    """hì¼ ë’¤ ìˆ˜ìµë¥ ì„ ê³„ì‚°í•©ë‹ˆë‹¤: Close[t+h]/Close[t]-1"""
    return close_df.shift(-h) / close_df - 1.0

def cross_sectional_ic(factor: pd.DataFrame, future_ret: pd.DataFrame, show_progress: bool = False) -> float:
    """
    ë‹¨ë©´ IC(Information Coefficient)ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    - ê° ì¼ìë³„ë¡œ ì¢…ëª© ë‹¨ë©´ ìƒê´€ê³„ìˆ˜ë¥¼ êµ¬í•œ ë’¤ í‰ê· í•©ë‹ˆë‹¤.
    - ë°ì´í„° ì •í•©ì„±(ê³µí†µ ì¸ë±ìŠ¤) ë° ìœ íš¨ í‘œë³¸ ìˆ˜(>=5)ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
    """
    try:
        common = factor.index.intersection(future_ret.index)
        if len(common) == 0:
            return float("nan")
            
        factor = factor.loc[common]
        future_ret = future_ret.loc[common]
        ics = []
        
        total_days = len(factor)
        # ì¼ìë³„ ì§„í–‰ìƒí™© ì¶œë ¥ ì™„ì „íˆ ì œê±° - ê°œì²´ë³„ ì§„í–‰ìƒí™©ë§Œ ìœ ì§€
        
        for i, (dt, row) in enumerate(factor.iterrows(), 1):
            x = row.values
            y = future_ret.loc[dt].values
            
            # ìœ íš¨í•œ ê°’ë§Œ ì„ íƒ
            mask = np.isfinite(x) & np.isfinite(y)
            if mask.sum() < 5:  # ìµœì†Œ 5ê°œ ë°ì´í„° í•„ìš”
                continue
                
            x_valid = x[mask]
            y_valid = y[mask]
            
            # ë³€ë™ì„± í™•ì¸ (ìƒìˆ˜ ê°’ ì œì™¸)
            if np.std(x_valid) < 1e-8 or np.std(y_valid) < 1e-8:
                continue
                
            # ìƒê´€ê³„ìˆ˜ ê³„ì‚°
            try:
                corr_matrix = np.corrcoef(x_valid, y_valid)
                if corr_matrix.shape == (2, 2):  # ì •ìƒì ì¸ 2x2 í–‰ë ¬
                    ic_val = corr_matrix[0, 1]
                    if np.isfinite(ic_val):
                        ics.append(ic_val)
            except:
                continue
                
        if len(ics) == 0:
            return float("nan")
        return float(np.mean(ics))
        
    except Exception as e:
        return float("nan")

def first_pc_vector(A: pd.DataFrame) -> np.ndarray:
    """
    PCAì˜ ì²« ë²ˆì§¸ ì£¼ì„±ë¶„ ë²¡í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    - ê²°ì¸¡/ë¬´í•œê°’ì€ 0ìœ¼ë¡œ ì •ë¦¬ í›„ í‰ê·  ì œê±°
    - SVD ì‹¤íŒ¨ ì‹œ ë‹¨ìœ„ ë²¡í„°ë¡œ ëŒ€ì²´
    """
    X = A.values
    X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)
    X = X - X.mean(axis=0, keepdims=True)
    try:
        U, S, Vt = np.linalg.svd(X, full_matrices=False)
        v = U[:, 0]
        v = v / (np.linalg.norm(v) + 1e-12)
        return v
    except np.linalg.LinAlgError:
        v = np.ones(X.shape[0], dtype=float)
        v /= np.linalg.norm(v) + 1e-12
        return v

def pca_similarity(A: pd.DataFrame, B: pd.DataFrame) -> float:
    """ë‘ í–‰ë ¬ì˜ 1ì£¼ì„±ë¶„ ë²¡í„° ê°„ ìƒê´€ê³„ìˆ˜(ìœ ì‚¬ë„)ë¥¼ ë°˜í™˜"""
    v1 = first_pc_vector(A)
    v2 = first_pc_vector(B)
    return float(np.corrcoef(v1, v2)[0,1])


def random_terminal(rng: random.Random) -> Node:
    """ë¬´ì‘ìœ„ ì…ë ¥ ë‹¨ë§ ë…¸ë“œ ìƒì„±(OHLCV, vwap, returns)"""
    t = rng.choice(TERMINALS)
    return Node(op="terminal", terminal_name=t)

def random_unary(rng: random.Random, child: Node) -> Node:
    """ë¬´ì‘ìœ„ ë‹¨í•­ ì—°ì‚°ì ë…¸ë“œ ìƒì„±(ìœˆë„ìš°/ê¸°ê°„ íŒŒë¼ë¯¸í„° í¬í•¨)"""
    op = rng.choice(DefaultSearchSpace.UNARY_POOL)
    params = {}
    if op in ("ts_rank", "sma", "stddev"):
        params["window"] = DefaultSearchSpace.random_window(rng)
    if op in ("delta", "delay"):
        params["period"] = DefaultSearchSpace.random_window(rng)
    if op in ("ts_max", "ts_min", "ts_argmax", "ts_argmin", "decay_linear"):
        params["window"] = DefaultSearchSpace.random_window(rng)
    return Node(op=op, left=child.copy(), params=params)

def random_binary(rng: random.Random, left: Node, right: Node) -> Node:
    """ë¬´ì‘ìœ„ ì´í•­ ì—°ì‚°ì ë…¸ë“œ ìƒì„±(correlationì˜ ê²½ìš° ìœˆë„ìš° í¬í•¨)"""
    op = rng.choice(DefaultSearchSpace.BINARY_POOL)
    params = {}
    if op == "correlation":
        params["window"] = DefaultSearchSpace.random_window(rng)
    return Node(op=op, left=left.copy(), right=right.copy(), params=params)

def random_tree(rng: random.Random, target_depth:int) -> Node:
    """ëª©í‘œ ê¹Šì´ì— ë§ì¶° ë¬´ì‘ìœ„ ìˆ˜ì‹ íŠ¸ë¦¬ ìƒì„±(ë‹¨í•­/ì´í•­ í˜¼í•©)"""
    if target_depth <= 1:
        return random_terminal(rng)
    if rng.random() < 0.5:
        child = random_tree(rng, target_depth-1)
        return random_unary(rng, child)
    else:
        left_depth = rng.randint(1, target_depth-1)
        right_depth = target_depth-1
        left = random_tree(rng, left_depth)
        right = random_tree(rng, right_depth)
        return random_binary(rng, left, right)

def mutate(rng: random.Random, node: Node, p_param: float=0.5) -> Node:
    """
    ë³€ì´ ì—°ì‚°
    - ì—°ì‚°ì êµì²´, íŒŒë¼ë¯¸í„° ì„­ë™, ì„œë¸ŒíŠ¸ë¦¬ ì¹˜í™˜ ì¤‘ í•˜ë‚˜ë¥¼ ë¬´ì‘ìœ„ ì„ íƒ
    - p_paramì€ íŒŒë¼ë¯¸í„° ë³€ì´ í™•ë¥ 
    """
    node = node.copy()
    choice = rng.random()
    if choice < 0.33 and node.op != "terminal":
        if node.op in UNARY_OPS:
            newop = rng.choice(DefaultSearchSpace.UNARY_POOL)
            node.op = newop
            node.params = {}
            if newop in ("ts_rank", "sma", "stddev"):
                node.params["window"] = DefaultSearchSpace.random_window(rng)
            if newop in ("delta", "delay"):
                node.params["period"] = DefaultSearchSpace.random_window(rng)
        elif node.op in BINARY_OPS:
            newop = rng.choice(DefaultSearchSpace.BINARY_POOL)
            node.op = newop
            node.params = {}
            if newop == "correlation":
                node.params["window"] = DefaultSearchSpace.random_window(rng)
    elif choice < 0.66:
        if node.op in UNARY_OPS:
            if "window" in node.params and rng.random() < p_param:
                node.params["window"] = DefaultSearchSpace.random_window(rng)
            if "period" in node.params and rng.random() < p_param:
                node.params["period"] = DefaultSearchSpace.random_window(rng)
        if node.op in BINARY_OPS and node.op == "correlation" and rng.random() < p_param:
            node.params["window"] = DefaultSearchSpace.random_window(rng)
    else:
        all_nodes = [n for n in node.iter_nodes() if n.op != "terminal"]
        if all_nodes:
            tgt = rng.choice(all_nodes)
            new_sub = random_tree(rng, max(1, tgt.depth()))
            tgt.op, tgt.left, tgt.right, tgt.params, tgt.terminal_name =                 new_sub.op, new_sub.left, new_sub.right, new_sub.params, new_sub.terminal_name
    return node

def crossover(rng: random.Random, a: Node, b: Node) -> Tuple[Node, Node]:
    """êµì°¨ ì—°ì‚°: ì„ì˜ ë…¸ë“œ ì„ íƒ í›„ êµ¬ì¡°/íŒŒë¼ë¯¸í„° ì„œë¡œ êµí™˜"""
    a = a.copy(); b = b.copy()
    a_nodes = list(a.iter_nodes())
    b_nodes = list(b.iter_nodes())
    a_pick = rng.choice(a_nodes)
    b_pick = rng.choice(b_nodes)
    a_pick.op, b_pick.op = b_pick.op, a_pick.op
    a_pick.left, b_pick.left = b_pick.left, a_pick.left
    a_pick.right, b_pick.right = b_pick.right, a_pick.right
    a_pick.params, b_pick.params = b_pick.params, a_pick.params
    a_pick.terminal_name, b_pick.terminal_name = b_pick.terminal_name, a_pick.terminal_name
    return a, b


@dataclass
class Individual:
    """ê°œì²´ í‘œí˜„: ìˆ˜ì‹ íŠ¸ë¦¬ + ì í•©ë„(ë‹¨ë©´ IC) + PCA ë²¡í„°/íŒ©í„°í–‰ë ¬ ìºì‹œ"""
    tree: Node
    fitness: float = float("nan")
    pca_vec: Optional[np.ndarray] = None
    factor_matrix: Optional[pd.DataFrame] = None

class AutoAlphaGA:
    """
    AutoAlpha ìŠ¤íƒ€ì¼ GA êµ¬í˜„ (ê°„ì´ IC ê¸°ë°˜ 1ì°¨ í‰ê°€ + PCA ë‹¤ì–‘ì„±)
    - df_data: Alphasê°€ ê¸°ëŒ€í•˜ëŠ” ì…ë ¥ ë”•ì…”ë„ˆë¦¬
    - hold_horizon: ë¯¸ë˜ ìˆ˜ìµë¥  ê³„ì‚° ì‹œì (h)
    - random_seed: ì¬í˜„ì„±
    """
    def __init__(self, df_data: Dict[str, pd.DataFrame], hold_horizon:int=1, random_seed:int=42):
        self.df_data = df_data
        self.h = int(hold_horizon)
        self.rng = random.Random(random_seed)

        self.ctx = Alphas(df_data)
        self.close_df = self.ctx.close
        self.future_ret = compute_future_returns(self.close_df, self.h)

        self.archive: List[Individual] = []
        self.record: List[Individual] = []

    def evaluate(self, ind: Individual) -> float:
        """
        ê°œì²´ ì í•©ë„ í‰ê°€
        - ìˆ˜ì‹ íŠ¸ë¦¬ë¥¼ ì‹¤í–‰í•˜ì—¬ íŒ©í„° í–‰ë ¬ ê³„ì‚°
        - ë¯¸ë˜ ìˆ˜ìµë¥ ê³¼ ì¼ìë³„ ë‹¨ë©´ ìƒê´€(IC) í‰ê· ì„ ì í•©ë„ë¡œ ì‚¬ìš©
        - ê³„ì‚° ì•ˆì „ì„± ìœ„í•´ inf/NaN â†’ 0 ì²˜ë¦¬
        """
        # í‰ê°€ íšŸìˆ˜ ì¶”ì  (ë„ˆë¬´ ë§ì´ ì¶œë ¥í•˜ì§€ ì•Šë„ë¡ ê°„í—ì ìœ¼ë¡œë§Œ)
        if not hasattr(self, '_eval_counter'):
            self._eval_counter = 0
        self._eval_counter += 1
        
        # ê°œì²´ê°€ ë„ˆë¬´ ë³µì¡í•˜ë©´ ìŠ¤í‚µ (ë¬´í•œë£¨í”„ ë°©ì§€)
        if ind.tree.depth() > 10:
            ind.fitness = 0.0
            return 0.0
            
        try:
            f = ind.tree.compile()
            val = f(self.ctx)
            
            # ê²°ê³¼ í˜•íƒœ ì •ê·œí™”
            if isinstance(val, pd.Series):
                try:
                    # MultiIndex Seriesë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
                    if isinstance(val.index, pd.MultiIndex):
                        factor_df = val.unstack()
                    else:
                        # ë‹¨ì¼ ì¸ë±ìŠ¤ Seriesë¥¼ self.close_dfì™€ ê°™ì€ shapeìœ¼ë¡œ ë¸Œë¡œë“œìºìŠ¤íŠ¸
                        if len(val) == len(self.close_df):
                            # ì‹œê°„ ì°¨ì›ì´ ë§ìœ¼ë©´ ëª¨ë“  ì¢…ëª©ì— ë™ì¼ ê°’ ì ìš©
                            factor_df = pd.DataFrame(
                                np.tile(val.values.reshape(-1, 1), (1, self.close_df.shape[1])),
                                index=self.close_df.index,
                                columns=self.close_df.columns
                            )
                        else:
                            # í¬ê¸°ê°€ ì•ˆ ë§ìœ¼ë©´ 0 í–‰ë ¬
                            factor_df = self.close_df * 0.0
                except Exception:
                    factor_df = self.close_df * 0.0
            elif isinstance(val, pd.DataFrame):
                factor_df = val
            else:
                # ìŠ¤ì¹¼ë¼ë‚˜ ë°°ì—´ì¸ ê²½ìš°
                factor_df = self.close_df * 0.0

            # ë°ì´í„° ì •ë¦¬
            factor_df = factor_df.replace([np.inf, -np.inf], 0).fillna(0)
            
            # í¬ê¸° ë§ì¶”ê¸°
            if factor_df.shape != self.close_df.shape:
                # ì¸ë±ìŠ¤/ì»¬ëŸ¼ ë§ì¶”ê¸°
                factor_df = factor_df.reindex(index=self.close_df.index, 
                                            columns=self.close_df.columns, 
                                            fill_value=0)

            # IC ê³„ì‚° (ì²« ë²ˆì§¸ì™€ ë§¤ 50ë²ˆì§¸ ê°œì²´ë§ˆë‹¤ ì§„í–‰ìƒí™© í‘œì‹œ)
            show_progress = (self._eval_counter == 1 or self._eval_counter % 50 == 0)
            ic = cross_sectional_ic(factor_df, self.future_ret, show_progress=show_progress)
            ind.fitness = float(ic) if np.isfinite(ic) else 0.0
            ind.factor_matrix = factor_df

            return ind.fitness
            
        except Exception as e:
            # ë””ë²„ê¹…ì„ ìœ„í•´ ê°€ë” ì—ëŸ¬ ë‚´ìš© ì¶œë ¥
            if self._eval_counter % 100 == 1:  # 100ë²ˆë§ˆë‹¤ í•œ ë²ˆë§Œ
                print(f"               âš ï¸ í‰ê°€ ì—ëŸ¬ (#{self._eval_counter}): {str(e)[:50]}...")
            # ê³„ì‚° ì‹¤íŒ¨ ì‹œ 0ì 
            ind.fitness = 0.0
            ind.factor_matrix = self.close_df * 0.0
            return 0.0

    def pca_sim_to_archive(self, ind: Individual, threshold: float = 0.9) -> float:
        """
        ì•„ì¹´ì´ë¸Œ ë‚´ ê°œì²´ë“¤ê³¼ 1ì£¼ì„±ë¶„ ë²¡í„° ìœ ì‚¬ë„ ìµœëŒ€ê°’ì„ ë°˜í™˜
        - threshold ë¯¸ë§Œì´ë©´ ì¶©ë¶„íˆ ë‹¤ì–‘í•˜ë‹¤ê³  íŒë‹¨
        """
        if ind.factor_matrix is None:
            return 0.0
        if ind.pca_vec is None:
            ind.pca_vec = first_pc_vector(ind.factor_matrix)
        sims = []
        for e in self.archive:
            if e.pca_vec is None and e.factor_matrix is not None:
                e.pca_vec = first_pc_vector(e.factor_matrix)
            if e.pca_vec is not None:
                sims.append(float(np.corrcoef(ind.pca_vec, e.pca_vec)[0,1]))
        return max(sims) if sims else 0.0

    def init_population(self, size:int, depth:int, warmstart_k:int=4) -> List[Individual]:
        """
        ì´ˆê¸° ê°œì²´êµ° ìƒì„±(ì›Œë°ìŠ¤íƒ€íŠ¸): ë£¨íŠ¸ í…œí”Œë¦¿ ê¸°ë°˜ í›„ë³´ Kë°° ìƒì„± í›„ ìƒìœ„ 1/K ì„ íƒ
        """
        cand: List[Individual] = []
        roots = DefaultSearchSpace.ROOT_TEMPLATES
        while len(cand) < size*warmstart_k and len(cand) < size*2:
            root = random.choice(roots).copy()
            while root.depth() < depth:
                if self.rng.random() < 0.5:
                    root = random_unary(self.rng, root)
                else:
                    root = random_binary(self.rng, root, random_terminal(self.rng))
            cand.append(Individual(tree=root))

        while len(cand) < size*warmstart_k:
            cand.append(Individual(tree=random_tree(self.rng, depth)))

        print(f"            ğŸ§® ê°œì²´ í‰ê°€ ì¤‘: {len(cand)}ê°œ í›„ë³´...")
        import time
        start_time = time.time()
        
        for i, ind in enumerate(cand, 1):
            ind_start = time.time()
            self.evaluate(ind)
            ind_time = time.time() - ind_start
            
            if i % 10 == 0 or i == len(cand):
                elapsed = time.time() - start_time
                avg_time = elapsed / i
                remaining = (len(cand) - i) * avg_time
                print(f"               [{i:3d}/{len(cand)}] í‰ê°€ ì™„ë£Œ (ê°œì²´ë‹¹ {ind_time:.2f}ì´ˆ, ì˜ˆìƒ ì”ì—¬ {remaining:.1f}ì´ˆ)...")
        
        print(f"            ğŸ“Š í‰ê°€ ì™„ë£Œ, ìƒìœ„ ì„ ë³„ ì¤‘...")
        cand.sort(key=lambda x: (-(x.fitness if np.isfinite(x.fitness) else -np.inf)))
        return cand[:max(1, len(cand)//warmstart_k)]

    def evolve_one_depth(self,
                         depth:int,
                         population:int,
                         generations:int,
                         warmstart_k:int=4,
                         n_keep:int=25,
                         p_mutation:float=0.3,
                         p_crossover:float=0.7,
                         diversity_threshold:float=0.9) -> List[Individual]:
        """
        ê³ ì • ê¹Šì´ì—ì„œì˜ ì§„í™” ë£¨í”„
        - ë¶€ëª¨-ìì‹ ì¹˜í™˜, ë‹¤ì–‘ì„±(1ì£¼ì„±ë¶„ ìœ ì‚¬ë„) í•„í„°, ì—˜ë¦¬íŠ¸ ë³´ê´€
        """
        print(f"         ğŸŒ± ê°œì²´êµ° ì´ˆê¸°í™” ì¤‘ (í¬ê¸°={population})...")
        pop = self.init_population(population, depth, warmstart_k=warmstart_k)
        
        # ì´ˆê¸° ê°œì²´êµ° ìƒíƒœ ì¶œë ¥
        valid_pop = [ind for ind in pop if np.isfinite(ind.fitness)]
        if valid_pop:
            best_init = max(ind.fitness for ind in valid_pop)
            avg_init = np.mean([ind.fitness for ind in valid_pop])
            print(f"         ğŸ“Š ì´ˆê¸° ê°œì²´êµ°: {len(valid_pop)}/{population}ê°œ ìœ íš¨, ìµœê³ IC={best_init:.6f}, í‰ê· IC={avg_init:.6f}")
        else:
            print(f"         âš ï¸ ì´ˆê¸° ê°œì²´êµ°: ìœ íš¨í•œ ê°œì²´ ì—†ìŒ")

        for ind in pop:
            if np.isfinite(ind.fitness) and (self.pca_sim_to_archive(ind, threshold=diversity_threshold) < diversity_threshold):
                self.archive.append(ind)

        print(f"         ğŸ”„ ì§„í™” ì‹œì‘ ({generations}ì„¸ëŒ€)...")
        for gen in range(generations):
            # ë§¤ 10ì„¸ëŒ€ë§ˆë‹¤ ë˜ëŠ” ë§ˆì§€ë§‰ ì„¸ëŒ€ì— ì§„í–‰ìƒí™© ì¶œë ¥
            if gen % 10 == 0 or gen == generations - 1:
                valid_current = [ind for ind in pop if np.isfinite(ind.fitness)]
                if valid_current:
                    best_current = max(ind.fitness for ind in valid_current)
                    avg_current = np.mean([ind.fitness for ind in valid_current])
                    print(f"            ğŸ§¬ ì„¸ëŒ€ {gen+1:3d}/{generations}: {len(valid_current)}ê°œ ìœ íš¨, ìµœê³ IC={best_current:.6f}, í‰ê· IC={avg_current:.6f}")
                else:
                    print(f"            ğŸ§¬ ì„¸ëŒ€ {gen+1:3d}/{generations}: ìœ íš¨í•œ ê°œì²´ ì—†ìŒ")
            parents = random.sample(pop, 2) if len(pop) >= 2 else pop
            if len(parents) < 2:
                child = mutate(self.rng, parents[0].tree)
                child_ind = Individual(tree=child)
                self.evaluate(child_ind)
                if child_ind.fitness > parents[0].fitness:
                    pop[0] = child_ind
                    if self.pca_sim_to_archive(child_ind, threshold=diversity_threshold) < diversity_threshold:
                        self.archive.append(child_ind)
                continue

            p1, p2 = parents[0], parents[1]

            children: List[Individual] = []
            if self.rng.random() < p_crossover:
                c1_tree, c2_tree = crossover(self.rng, p1.tree, p2.tree)
                children += [Individual(c1_tree), Individual(c2_tree)]
            if self.rng.random() < p_mutation:
                children += [Individual(mutate(self.rng, p1.tree)),
                             Individual(mutate(self.rng, p2.tree))]
            if not children:
                children = [Individual(mutate(self.rng, p1.tree))]

            for ch in children:
                self.evaluate(ch)
                best_parent = p1 if p1.fitness >= p2.fitness else p2
                if ch.fitness > best_parent.fitness:
                    try:
                        idx = pop.index(best_parent)
                        pop[idx] = ch
                    except ValueError:
                        pass
                    if self.pca_sim_to_archive(ch, threshold=diversity_threshold) < diversity_threshold:
                        self.archive.append(ch)

            pop.sort(key=lambda x: (-(x.fitness if np.isfinite(x.fitness) else -np.inf)))
            pop = pop[:population]

        pop.sort(key=lambda x: (-(x.fitness if np.isfinite(x.fitness) else -np.inf)))
        elites = []
        for ind in pop:
            if len(elites) >= n_keep:
                break
            if self.pca_sim_to_archive(ind, threshold=diversity_threshold) < diversity_threshold:
                elites.append(ind)
        return elites

    def run(self,
            max_depth:int=3,
            population:int=60,
            generations:int=20,
            warmstart_k:int=4,
            n_keep_per_depth:int=25,
            p_mutation:float=0.3,
            p_crossover:float=0.7,
            diversity_threshold:float=0.9) -> List[Individual]:
        """
        ê¹Šì´ë¥¼ 1â†’max_depthê¹Œì§€ í™•ì¥í•˜ë©° ìˆœì°¨ íƒìƒ‰ í›„, ì „ì²´ ì—˜ë¦¬íŠ¸ ì •ë ¬ ë°˜í™˜
        """
        print(f"      ğŸ—ï¸ ê³„ì¸µì  íƒìƒ‰ ì‹œì‘ (ê¹Šì´ 1â†’{max_depth})")
        all_elites: List[Individual] = []
        
        for depth in range(1, max_depth+1):
            print(f"      ğŸ“ [ê¹Šì´ {depth}/{max_depth}] ì§„í™” ì‹œì‘...")
            elites = self.evolve_one_depth(
                depth=depth,
                population=population,
                generations=generations,
                warmstart_k=warmstart_k,
                n_keep=n_keep_per_depth,
                p_mutation=p_mutation,
                p_crossover=p_crossover,
                diversity_threshold=diversity_threshold,
            )
            all_elites.extend(elites)
            
            # í•´ë‹¹ ê¹Šì´ ê²°ê³¼ ìš”ì•½
            valid_elites = [e for e in elites if np.isfinite(e.fitness)]
            if valid_elites:
                best_ic = max(e.fitness for e in valid_elites)
                avg_ic = np.mean([e.fitness for e in valid_elites])
                print(f"         âœ… ì™„ë£Œ: {len(valid_elites)}ê°œ ì—˜ë¦¬íŠ¸, ìµœê³ IC={best_ic:.6f}, í‰ê· IC={avg_ic:.6f}")
            else:
                print(f"         âš ï¸ ì™„ë£Œ: ìœ íš¨í•œ ì—˜ë¦¬íŠ¸ ì—†ìŒ")
        
        all_elites.sort(key=lambda x: (-(x.fitness if np.isfinite(x.fitness) else -np.inf)))
        valid_total = len([e for e in all_elites if np.isfinite(e.fitness)])
        print(f"      ğŸ¯ ê³„ì¸µì  íƒìƒ‰ ì™„ë£Œ: ì´ {valid_total}ê°œ ìœ íš¨ ì—˜ë¦¬íŠ¸")
        
        return all_elites


HEADER = '''# -*- coding: utf-8 -*-
"""
ìë™ ìƒì„±ëœ ì•ŒíŒŒ ëª¨ìŒ (GA ê²°ê³¼)
- íŒŒì¼ ìƒì„±ì‹œê°: {ts}
- ì°¸ê³ : autoalpha_ga.write_new_alphas_file()ê°€ ìƒì„±
ì£¼ì˜: ìˆ˜ë™ ìˆ˜ì • ì‹œ ì¬ìƒì„± ì‹œ ë®ì–´ì”Œì›Œì§‘ë‹ˆë‹¤.
"""

import pandas as pd
import numpy as np
from Alphas import (
    Alphas,
    ts_sum, sma, stddev, correlation, covariance,
    ts_rank, product, ts_min, ts_max, delta, delay, rank, scale,
    ts_argmax, ts_argmin, decay_linear,
    safe_clean, adv, floor_window
)

# min/max ì—°ì‚°ì„ ìœ„í•œ numpy import í™•ì‹¤íˆ í•˜ê¸°
import numpy as np

class NewAlphas(Alphas):
    """
    GAë¡œ ë°œêµ´ëœ ì•ŒíŒŒ íŒ©í„° ëª¨ìŒ.
    ê° ë©”ì„œë“œëŠ” pandas Series(ë˜ëŠ” DataFrameì˜ ì—´ ì‹œë¦¬ì¦ˆ)ë¥¼ ë°˜í™˜í•´ì•¼ í•©ë‹ˆë‹¤.
    """
'''

def write_new_alphas_file(elites: List[Individual], out_path: Optional[str] = None):
    """
    ìƒìœ„ ê°œì²´ë“¤ì„ `backend_module/NewAlphas.py`ë¡œ ì§ë ¬í™”í•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤.
    - out_pathë¥¼ ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ ì´ íŒŒì¼ ê¸°ì¤€ ìƒëŒ€ê²½ë¡œë¡œ backend_module/NewAlphas.pyì— ê¸°ë¡í•©ë‹ˆë‹¤.
    - ê¸°ì¡´ íŒŒì¼ì€ ë®ì–´ì”Œì›Œì§‘ë‹ˆë‹¤.
    """
    if out_path is None:
        # í´ë” ì¡´ì¬ í™•ì¸ ë° ìƒì„±
        os.makedirs(BACKEND_MODULE_DIR, exist_ok=True)
        out_path = os.path.join(BACKEND_MODULE_DIR, "NewAlphas.py")

    lines = [HEADER.format(ts=pd.Timestamp.utcnow().strftime("%Y-%m-%d %H:%M:%S UTC"))]
    for i, ind in enumerate(elites, start=1):
        name = f"alphaGA{i:03d}"
        expr = ind.tree.to_python_expr()
        body = f"        out = ({expr})\n        return out.replace([np.inf, -np.inf], 0).fillna(0)\n"
        func = f"    def {name}(self):\n{body}\n"
        lines.append(func)

    with open(out_path, "w", encoding="utf-8") as f:
        f.write("\n".join(lines))
    return out_path


if __name__ == "__main__":
    msg = (
        "[AutoAlpha GA]\n"
        "- ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ í˜•íƒœì…ë‹ˆë‹¤.\n"
        "- ì‹¤ì œ ì‹¤í–‰ ì‹œì—ëŠ” ì‚¬ìš©ì ë°ì´í„°(df_data)ë¥¼ êµ¬ì„±í•˜ì—¬ AutoAlphaGA(df_data)ë¡œ ìƒì„±í•˜ì„¸ìš”.\n"
        "- run() í˜¸ì¶œ í›„ write_new_alphas_file()ë¡œ NewAlphas.pyë¥¼ ìƒì„±í•˜ì„¸ìš”.\n"
    )
    print(msg)
