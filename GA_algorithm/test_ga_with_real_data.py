#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì‹¤ì œ ë°ì´í„°ë¡œ AutoAlpha GA í…ŒìŠ¤íŠ¸
- database/sp500_interpolated.csv ë°ì´í„° ì‚¬ìš©
- ì†Œê·œëª¨ ìƒ˜í”Œë¡œ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸
"""

import os
import sys
import pandas as pd
import numpy as np
from datetime import datetime

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì •
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(CURRENT_DIR)
DATABASE_DIR = os.path.join(PROJECT_ROOT, 'database')
BACKEND_MODULE_DIR = os.path.join(PROJECT_ROOT, 'backend_module')

# ê²½ë¡œ ì¶”ê°€
if BACKEND_MODULE_DIR not in sys.path:
    sys.path.insert(0, BACKEND_MODULE_DIR)
if CURRENT_DIR not in sys.path:
    sys.path.insert(0, CURRENT_DIR)

def load_sample_data(n_stocks=50, n_days=500):
    """
    ì‹¤ì œ ë°ì´í„°ì—ì„œ ì†Œê·œëª¨ ìƒ˜í”Œ ì¶”ì¶œ
    - Alphas í´ë˜ìŠ¤ê°€ ê¸°ëŒ€í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    """
    print("ğŸ“¥ ì‹¤ì œ ë°ì´í„° ë¡œë”© ì¤‘...")
    
    # CSV íŒŒì¼ ê²½ë¡œ
    data_file = os.path.join(DATABASE_DIR, 'sp500_interpolated.csv')
    
    if not os.path.exists(data_file):
        print(f"âŒ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {data_file}")
        return None
    
    # ë°ì´í„° ìƒ˜í”Œ ë¡œë“œ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ì„ ìœ„í•´ ì²­í¬ ì‚¬ìš©)
    print(f"   íŒŒì¼: {data_file}")
    
    try:
        # ë” ë§ì€ ë°ì´í„° ë¡œë“œ (ì—¬ëŸ¬ ì²­í¬ í•©ì¹˜ê¸°)
        chunk_iter = pd.read_csv(data_file, chunksize=50000, parse_dates=['Date'])
        chunks = []
        for i, chunk in enumerate(chunk_iter):
            chunks.append(chunk)
            if i >= 4:  # ìµœëŒ€ 5ê°œ ì²­í¬ (ì•½ 250K í–‰)
                break
        
        all_data = pd.concat(chunks, ignore_index=True)
        
        print(f"   ë¡œë“œëœ ë°ì´í„°: {len(all_data):,} í–‰")
        print(f"   ì „ì²´ ì»¬ëŸ¼: {list(all_data.columns)}")
        print(f"   ì „ì²´ ê¸°ê°„: {all_data['Date'].min()} ~ {all_data['Date'].max()}")
        print(f"   ì „ì²´ ì¢…ëª© ìˆ˜: {all_data['Ticker'].nunique()}")
        
        # ìƒìœ„ n_stocks ì¢…ëª©ë§Œ ì„ íƒ (ë°ì´í„°ê°€ ë§ì€ ì¢…ëª© ìš°ì„ )
        top_tickers = all_data['Ticker'].value_counts().head(n_stocks).index.tolist()
        print(f"   ì„ íƒëœ ì¢…ëª©: {top_tickers[:10]}...")  # ì²˜ìŒ 10ê°œë§Œ ì¶œë ¥
        
        # í•„í„°ë§: ê° ì¢…ëª©ë³„ë¡œ ìµœì‹  n_daysë§Œ ì„ íƒ
        sample_data_list = []
        for ticker in top_tickers:
            ticker_data = all_data[all_data['Ticker'] == ticker].sort_values('Date').tail(n_days)
            if len(ticker_data) > 0:  # ë°ì´í„°ê°€ ìˆëŠ” ì¢…ëª©ë§Œ
                sample_data_list.append(ticker_data)
        
        if not sample_data_list:
            print("âŒ ìœ íš¨í•œ ì¢…ëª© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return None
            
        sample_data = pd.concat(sample_data_list, ignore_index=True).sort_values(['Date', 'Ticker'])
        
        print(f"   ìµœì¢… ìƒ˜í”Œ í¬ê¸°: {len(sample_data)} í–‰")
        
        # Alphas í´ë˜ìŠ¤ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        df_data = {}
        
        # í”¼ë²—: (Date x Ticker) í˜•íƒœë¡œ ë³€í™˜
        for col_name, target_name in [
            ('Open', 'S_DQ_OPEN'),
            ('High', 'S_DQ_HIGH'), 
            ('Low', 'S_DQ_LOW'),
            ('Close', 'S_DQ_CLOSE'),
            ('Volume', 'S_DQ_VOLUME')
        ]:
            if col_name in sample_data.columns:
                try:
                    pivot_df = sample_data.pivot(index='Date', columns='Ticker', values=col_name)
                    # ê²°ì¸¡ì¹˜ë¥¼ ì „ì§„ ì±„ì›€ í›„ 0ìœ¼ë¡œ ì±„ì›€
                    pivot_df = pivot_df.ffill().fillna(0)
                    df_data[target_name] = pivot_df
                    print(f"   âœ… {target_name}: {pivot_df.shape}")
                except Exception as e:
                    print(f"   âŒ {target_name} ë³€í™˜ ì‹¤íŒ¨: {e}")
                    continue
        
        # íŒŒìƒ ì»¬ëŸ¼ ê³„ì‚°
        if 'S_DQ_CLOSE' in df_data and 'S_DQ_VOLUME' in df_data:
            try:
                # ê±°ë˜ëŒ€ê¸ˆ (Amount)
                df_data['S_DQ_AMOUNT'] = df_data['S_DQ_CLOSE'] * df_data['S_DQ_VOLUME']
                df_data['S_DQ_AMOUNT'] = df_data['S_DQ_AMOUNT'].replace([np.inf, -np.inf], 0).fillna(0)
                
                # ìˆ˜ìµë¥  (PctChange) - ë” ì•ˆì „í•œ ê³„ì‚°
                close_df = df_data['S_DQ_CLOSE']
                pct_change = close_df.pct_change(fill_method=None)
                df_data['S_DQ_PCTCHANGE'] = pct_change.replace([np.inf, -np.inf], 0).fillna(0)
                
                print(f"   âœ… S_DQ_AMOUNT: {df_data['S_DQ_AMOUNT'].shape}")
                print(f"   âœ… S_DQ_PCTCHANGE: {df_data['S_DQ_PCTCHANGE'].shape}")
            except Exception as e:
                print(f"   âŒ íŒŒìƒ ì»¬ëŸ¼ ê³„ì‚° ì‹¤íŒ¨: {e}")
        
        # ìµœì¢… ë°ì´í„° ê²€ì¦
        if len(df_data) < 5:
            print("âŒ í•„ìˆ˜ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤")
            return None
            
        # ëª¨ë“  DataFrame í¬ê¸° í†µì¼
        base_shape = None
        for key, df in df_data.items():
            if base_shape is None:
                base_shape = df.shape
            elif df.shape != base_shape:
                print(f"   âš ï¸ {key} í¬ê¸° ë¶ˆì¼ì¹˜: {df.shape} vs {base_shape}")
        
        # ìµœì¢… ê²°ì¸¡ì¹˜ ì²˜ë¦¬
        for key, df in df_data.items():
            df_data[key] = df.ffill().fillna(0)
        
        print("âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ!")
        return df_data
        
    except Exception as e:
        print(f"âŒ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {e}")
        return None

def test_autoalpha_ga():
    """AutoAlpha GA í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("ğŸ§¬ AutoAlpha GA í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 50)
    
    # 1. ë°ì´í„° ë¡œë“œ (ë” ë§ì€ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸)
    df_data = load_sample_data(n_stocks=30, n_days=200)
    if df_data is None:
        print("âŒ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨ë¡œ í…ŒìŠ¤íŠ¸ ì¤‘ë‹¨")
        return
    
    # 2. AutoAlpha GA ì‹¤í–‰
    try:
        from autoalpha_ga import AutoAlphaGA, write_new_alphas_file
        
        print("\nğŸš€ GA ì´ˆê¸°í™”...")
        ga = AutoAlphaGA(df_data, hold_horizon=1, random_seed=42)
        
        print("ğŸ”„ ì§„í™” ì•Œê³ ë¦¬ì¦˜ ì‹¤í–‰...")
        elites = ga.run(
            max_depth=3,        # ë” ë³µì¡í•œ ìˆ˜ì‹ê¹Œì§€ íƒìƒ‰
            population=20,      # ë” í° ê°œì²´êµ°
            generations=10,     # ë” ë§ì€ ì„¸ëŒ€
            warmstart_k=4,
            n_keep_per_depth=10,
            p_mutation=0.3,
            p_crossover=0.7,
        )
        
        print(f"\nğŸ† ë°œê²¬ëœ ì—˜ë¦¬íŠ¸: {len(elites)}ê°œ")
        
        # ìƒìœ„ 5ê°œ ê²°ê³¼ ì¶œë ¥ (ìœ íš¨í•œ ICë§Œ)
        valid_elites = [e for e in elites if not np.isnan(e.fitness)]
        print(f"   ìœ íš¨í•œ ì—˜ë¦¬íŠ¸: {len(valid_elites)}ê°œ")
        
        for i, elite in enumerate(valid_elites[:5], 1):
            print(f"  {i}. ì í•©ë„(IC): {elite.fitness:.6f}")
            print(f"     ìˆ˜ì‹: {elite.tree.to_python_expr()}")
            print(f"     ê¹Šì´: {elite.tree.depth()}")
            print()
        
        # 3. NewAlphas.py ìƒì„±
        if elites:
            print(f"\nğŸ“ ìƒìœ„ {min(3, len(elites))}ê°œë¥¼ NewAlphas.pyë¡œ ì €ì¥...")
            out_path = write_new_alphas_file(elites[:3])
            print(f"âœ… ì €ì¥ ì™„ë£Œ: {out_path}")
        
        print("\nğŸ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        
    except ImportError as e:
        print(f"âŒ ì„í¬íŠ¸ ì˜¤ë¥˜: {e}")
        print("í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”: pip install numpy pandas scipy")
    except Exception as e:
        print(f"âŒ GA ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_autoalpha_ga()
