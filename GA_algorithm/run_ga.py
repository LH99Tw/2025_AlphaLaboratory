
# -*- coding: utf-8 -*-
"""
GA Runner: ì§„í™”ì•Œê³ ë¦¬ì¦˜ ì‹¤í–‰ + NewAlphas.py ìƒì„± + ì•ŒíŒŒ CSV ìƒì„±(+ì˜µì…˜ ë°±í…ŒìŠ¤íŠ¸)
-------------------------------------------------------------------------------
ì‚¬ìš©ë²• ì˜ˆì‹œ:
    python run_ga.py \
        --price-file ./database/sp500_interpolated.csv \
        --alpha-out  ./database/sp500_with_alphas.csv \
        --max-depth 3 --population 60 --generations 20 \
        --topk 10 --run-backtest

í•„ìš” ê²½ë¡œ ê°€ì •(ê¸°ë³¸ê°’):
- backend_module/Alphas.py (ì—°ì‚°ì/ì…ë ¥ í´ë˜ìŠ¤)
- backend_module/NewAlphas.py (GAê°€ ìë™ ìƒì„±/ë®ì–´ì”€)
- 5_results.py ë° backtest_config.json (ë°±í…ŒìŠ¤íŠ¸ ì„¤ì •)

ë©”ëª¨:
- price CSVëŠ” ìµœì†Œí•œ Date, Ticker, Open, High, Low, Close, Volume ì»¬ëŸ¼ì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
- S_DQ_AMOUNT(ê±°ë˜ëŒ€ê¸ˆ)ëŠ” ì—†ì„ ê²½ìš° Close*Volumeìœ¼ë¡œ ê·¼ì‚¬ ì‚°ì¶œí•©ë‹ˆë‹¤.
"""

import os
import sys
import argparse
import pandas as pd
import numpy as np
from datetime import datetime

# ---------- ê²½ë¡œ ì„¤ì • ----------
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(CURRENT_DIR)  # GA_algorithmì˜ ìƒìœ„ í´ë” (2025_sang2company)
BACKEND_MODULE_DIR = os.path.join(PROJECT_ROOT, 'backend_module')
if BACKEND_MODULE_DIR not in sys.path:
    sys.path.insert(0, BACKEND_MODULE_DIR)

# autoalpha_ga.py ëŠ” í”„ë¡œì íŠ¸ ë£¨íŠ¸(ë˜ëŠ” PYTHONPATH) ìƒì— ìœ„ì¹˜í•œë‹¤ê³  ê°€ì •
try:
    from autoalpha_ga import AutoAlphaGA, write_new_alphas_file
except ImportError as e:
    print("âŒ autoalpha_ga ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. run_ga.pyì™€ ê°™ì€ í´ë”ì— ë‘ê±°ë‚˜ PYTHONPATHì— ì¶”ê°€í•˜ì„¸ìš”.")
    raise

# Alphas/NewAlphas
try:
    from Alphas import Alphas
except ImportError:
    print("âŒ backend_module/Alphas.py ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í´ë”/ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    raise


def parse_args():
    ap = argparse.ArgumentParser()
    ap.add_argument("--price-file", type=str, default=os.path.join(PROJECT_ROOT, "database", "sp500_interpolated.csv"))
    ap.add_argument("--alpha-out",  type=str, default=os.path.join(PROJECT_ROOT, "database", "sp500_with_alphas.csv"))
    ap.add_argument("--start-date", type=str, default=None, help="YYYY-MM-DD (ì—†ìœ¼ë©´ ì „ì²´)")
    ap.add_argument("--end-date",   type=str, default=None, help="YYYY-MM-DD (ì—†ìœ¼ë©´ ì „ì²´)")
    ap.add_argument("--hold-h",     type=int, default=1, help="IC ê³„ì‚°ìš© ë¯¸ë˜ìˆ˜ìµ ê¸°ê°„ h")
    ap.add_argument("--random-seed", type=int, default=42)

    # GA í•˜ì´í¼íŒŒë¼ë¯¸í„°
    ap.add_argument("--max-depth", type=int, default=3)
    ap.add_argument("--population", type=int, default=60)
    ap.add_argument("--generations", type=int, default=20)
    ap.add_argument("--warmstart-k", type=int, default=4)
    ap.add_argument("--keep-per-depth", type=int, default=25)
    ap.add_argument("--p-mutation", type=float, default=0.3)
    ap.add_argument("--p-crossover", type=float, default=0.7)
    ap.add_argument("--diversity-th", type=float, default=0.9)

    # ê²°ê³¼ ìƒì„±
    ap.add_argument("--topk", type=int, default=10, help="NewAlphas.pyë¡œ ì €ì¥/CSVë¡œ ê³„ì‚°í•  ìƒìœ„ ì•ŒíŒŒ ìˆ˜")
    ap.add_argument("--run-backtest", action="store_true")

    return ap.parse_args()


def load_price_csv(price_file: str) -> pd.DataFrame:
    print(f"ğŸ“¥ ì£¼ê°€ ë°ì´í„° ë¡œë”© ì¤‘: {price_file}")
    if not os.path.exists(price_file):
        raise FileNotFoundError(f"ì£¼ê°€ CSVë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {price_file}")
    
    print("   CSV íŒŒì¼ ì½ëŠ” ì¤‘...")
    df = pd.read_csv(price_file)
    print(f"   âœ… ë¡œë“œ ì™„ë£Œ: {len(df):,}í–‰ Ã— {len(df.columns)}ì»¬ëŸ¼")
    
    # ìµœì†Œ ì»¬ëŸ¼ ìœ íš¨ì„± ì²´í¬
    required = {"Date", "Ticker", "Open", "High", "Low", "Close", "Volume"}
    missing = required - set(df.columns)
    if missing:
        raise ValueError(f"price_fileì— í•„ìš”í•œ ì»¬ëŸ¼ ëˆ„ë½: {missing}")
    print(f"   âœ… í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸ ì™„ë£Œ: {required}")
    
    # ë‚ ì§œ ì •ê·œí™”
    print("   ğŸ“… ë‚ ì§œ íŒŒì‹± ì¤‘...")
    df["Date"] = pd.to_datetime(df["Date"])
    print(f"   âœ… ê¸°ê°„: {df['Date'].min().date()} ~ {df['Date'].max().date()}")
    print(f"   âœ… ì¢…ëª© ìˆ˜: {df['Ticker'].nunique()}")
    
    return df


def make_df_data_from_prices(price_df: pd.DataFrame, start_date=None, end_date=None):
    print("ğŸ”„ Alphas í˜•ì‹ìœ¼ë¡œ ë°ì´í„° ë³€í™˜ ì¤‘...")
    
    # ê¸°ê°„ ìŠ¬ë¼ì´ìŠ¤
    original_len = len(price_df)
    if start_date:
        price_df = price_df[price_df["Date"] >= pd.to_datetime(start_date)]
        print(f"   ğŸ“… ì‹œì‘ì¼ í•„í„°: {start_date} â†’ {len(price_df):,}í–‰")
    if end_date:
        price_df = price_df[price_df["Date"] <= pd.to_datetime(end_date)]
        print(f"   ğŸ“… ì¢…ë£Œì¼ í•„í„°: {end_date} â†’ {len(price_df):,}í–‰")
    
    if len(price_df) == 0:
        raise ValueError("ê¸°ê°„ í•„í„°ë§ í›„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!")
    
    print(f"   âœ… í•„í„°ë§ ì™„ë£Œ: {original_len:,} â†’ {len(price_df):,}í–‰")

    # í”¼ë²—: (T x N)
    print("   ğŸ”„ í”¼ë²— í…Œì´ë¸” ìƒì„± ì¤‘...")
    def pivot(col):
        return price_df.pivot(index="Date", columns="Ticker", values=col).sort_index()

    print("      - Open...")
    open_df   = pivot("Open")
    print("      - High...")
    high_df   = pivot("High")
    print("      - Low...")
    low_df    = pivot("Low")
    print("      - Close...")
    close_df  = pivot("Close")
    print("      - Volume...")
    vol_df    = pivot("Volume")
    
    print(f"   âœ… í”¼ë²— ì™„ë£Œ: {open_df.shape} (ì¼ìˆ˜ Ã— ì¢…ëª©ìˆ˜)")

    # ê±°ë˜ëŒ€ê¸ˆ(ì—†ìœ¼ë©´ Close*Volume ê·¼ì‚¬)
    print("   ğŸ’° ê±°ë˜ëŒ€ê¸ˆ ê³„ì‚° ì¤‘...")
    if "Amount" in price_df.columns:
        amt_df = pivot("Amount")
        print("      - Amount ì»¬ëŸ¼ ì‚¬ìš©")
    else:
        amt_df = (close_df * vol_df).astype(float)
        print("      - Close Ã— Volumeìœ¼ë¡œ ê·¼ì‚¬ ê³„ì‚°")

    # ìˆ˜ìµë¥ (PCTCHANGE) - ì¢…ëª©ë³„ ì¼ê°„ ìˆ˜ìµë¥ 
    print("   ğŸ“ˆ ìˆ˜ìµë¥  ê³„ì‚° ì¤‘...")
    pct_df = close_df.pct_change(fill_method=None).fillna(0.0)

    print("   ğŸ”§ ìµœì¢… ë°ì´í„° êµ¬ì¡° ìƒì„± ì¤‘...")
    df_data = {
        'S_DQ_OPEN':   open_df.astype(float),
        'S_DQ_HIGH':   high_df.astype(float),
        'S_DQ_LOW':    low_df.astype(float),
        'S_DQ_CLOSE':  close_df.astype(float),
        'S_DQ_VOLUME': vol_df.astype(float),
        'S_DQ_PCTCHANGE': pct_df.astype(float),
        'S_DQ_AMOUNT': amt_df.astype(float),
    }
    
    print(f"   âœ… ë°ì´í„° ë³€í™˜ ì™„ë£Œ!")
    for key, df in df_data.items():
        print(f"      - {key}: {df.shape}")
    
    return df_data


def compute_topk_alphas_to_csv(df_data, top_methods, alpha_out_path):
    """
    NewAlphas.pyë¥¼ importí•˜ì—¬ top_methodsì— ëŒ€í•œ ì•ŒíŒŒ ê°’ ê³„ì‚° í›„ CSV ì €ì¥
    - ì¶œë ¥ í˜•ì‹: Date, Ticker, alphaGA001, alphaGA002, ...
    """
    print(f"ğŸ§® GA ì•ŒíŒŒë“¤ì„ CSVë¡œ ê³„ì‚° ì¤‘... ({len(top_methods)}ê°œ)")
    
    # NewAlphas import (ìƒì„±ëœ íŒŒì¼ì„ ë‹¤ì‹œ ë¡œë“œí•˜ë„ë¡)
    if BACKEND_MODULE_DIR not in sys.path:
        sys.path.insert(0, BACKEND_MODULE_DIR)
    try:
        print("   ğŸ“¥ NewAlphas.py ì„í¬íŠ¸ ì¤‘...")
        from NewAlphas import NewAlphas  # ìƒì„± ì§í›„ ì¬ì„í¬íŠ¸
        print("   âœ… NewAlphas ì„í¬íŠ¸ ì„±ê³µ")
    except Exception as e:
        print("âŒ backend_module/NewAlphas.py import ì‹¤íŒ¨:", e)
        raise

    print("   ğŸ”§ NewAlphas ì»¨í…ìŠ¤íŠ¸ ìƒì„± ì¤‘...")
    ctx = NewAlphas(df_data)
    print("   âœ… ì»¨í…ìŠ¤íŠ¸ ìƒì„± ì™„ë£Œ")

    panel_list = []
    for i, meth in enumerate(top_methods, 1):
        if not hasattr(ctx, meth):
            print(f"âš ï¸ {meth} ê°€ NewAlphasì— ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœ€.")
            continue
        print(f"   ğŸ§® [{i}/{len(top_methods)}] ê³„ì‚° ì¤‘: {meth}")
        s = getattr(ctx, meth)()
        # Series/DataFrame ëª¨ë‘ ìˆ˜ìš© -> DataFrame(T x N)ë¡œ ì •ê·œí™”
        if isinstance(s, pd.Series):
            if isinstance(s.index, pd.MultiIndex):
                fac_df = s.unstack()
            else:
                # ë‹¨ì¼ ì¸ë±ìŠ¤ë©´ ëª¨ë“  Tickerì— ë³µì œ(ë³´ìˆ˜ì  ëŒ€ì•ˆ)
                fac_df = pd.DataFrame(
                    np.tile(s.values.reshape(-1,1), (1, df_data['S_DQ_CLOSE'].shape[1])),
                    index=df_data['S_DQ_CLOSE'].index, columns=df_data['S_DQ_CLOSE'].columns
                )
        else:
            fac_df = s
        fac_df = fac_df.replace([np.inf, -np.inf], 0).fillna(0)
        # ë„“ì€ í¬ë§· -> ê¸¸ê²Œ
        long = fac_df.stack().reset_index()
        long.columns = ["Date","Ticker", meth]
        panel_list.append(long)

    if not panel_list:
        raise RuntimeError("ê³„ì‚°ëœ ì•ŒíŒŒê°€ ì—†ìŠµë‹ˆë‹¤. top_methodsë¥¼ í™•ì¸í•˜ì„¸ìš”.")

    print(f"   ğŸ”— {len(panel_list)}ê°œ ì•ŒíŒŒ ë°ì´í„° ë³‘í•© ì¤‘...")
    # ë³‘í•©
    merged = panel_list[0]
    for i, df in enumerate(panel_list[1:], 2):
        print(f"      - [{i}/{len(panel_list)}] ë³‘í•© ì¤‘...")
        merged = merged.merge(df, on=["Date","Ticker"], how="outer")
    
    print("   ğŸ“Š ì •ë ¬ ë° ì •ë¦¬ ì¤‘...")
    merged = merged.sort_values(["Date","Ticker"]).reset_index(drop=True)

    # ì €ì¥
    print(f"   ğŸ’¾ CSV ì €ì¥ ì¤‘: {alpha_out_path}")
    out_dir = os.path.dirname(alpha_out_path)
    if out_dir and not os.path.exists(out_dir):
        os.makedirs(out_dir, exist_ok=True)
    merged.to_csv(alpha_out_path, index=False, encoding="utf-8")
    print(f"   âœ… ì•ŒíŒŒ CSV ì €ì¥ ì™„ë£Œ!")
    print(f"      - íŒŒì¼: {alpha_out_path}")
    print(f"      - í¬ê¸°: {len(merged):,}í–‰ Ã— {len(merged.columns)}ì»¬ëŸ¼")
    print(f"      - ì»¬ëŸ¼: {list(merged.columns)}")
    return merged


def main():
    print("ğŸš€ AutoAlpha GA Runner ì‹œì‘")
    print("=" * 60)
    
    args = parse_args()
    
    print(f"ğŸ“‹ ì‹¤í–‰ íŒŒë¼ë¯¸í„°:")
    print(f"   - ì£¼ê°€íŒŒì¼: {args.price_file}")
    print(f"   - ì•ŒíŒŒì¶œë ¥: {args.alpha_out}")
    print(f"   - ê¸°ê°„: {args.start_date} ~ {args.end_date}")
    print(f"   - GA íŒŒë¼ë¯¸í„°: depth={args.max_depth}, pop={args.population}, gen={args.generations}")
    print(f"   - ìƒìœ„ ì•ŒíŒŒ: {args.topk}ê°œ")
    print()

    # 1) ë°ì´í„° ë¡œë“œ
    print("ğŸ”¸ 1ë‹¨ê³„: ë°ì´í„° ë¡œë“œ")
    price_df = load_price_csv(args.price_file)
    df_data_train = make_df_data_from_prices(price_df, args.start_date, args.end_date)
    print("âœ… 1ë‹¨ê³„ ì™„ë£Œ\n")

    # 2) GA ì‹¤í–‰
    print("ğŸ”¸ 2ë‹¨ê³„: ì§„í™” ì•Œê³ ë¦¬ì¦˜ ì‹¤í–‰")
    print(f"   ğŸ§¬ AutoAlpha GA ì´ˆê¸°í™” ì¤‘...")
    ga = AutoAlphaGA(df_data_train, hold_horizon=args.hold_h, random_seed=args.random_seed)
    print(f"   âœ… GA ì´ˆê¸°í™” ì™„ë£Œ")
    
    print(f"   ğŸ”„ ì§„í™” ì‹œì‘...")
    print(f"      - ìµœëŒ€ ê¹Šì´: {args.max_depth}")
    print(f"      - ê°œì²´êµ° í¬ê¸°: {args.population}")
    print(f"      - ì„¸ëŒ€ ìˆ˜: {args.generations}")
    
    elites = ga.run(
        max_depth=args.max_depth,
        population=args.population,
        generations=args.generations,
        warmstart_k=args.warmstart_k,
        n_keep_per_depth=args.keep_per_depth,
        p_mutation=args.p_mutation,
        p_crossover=args.p_crossover,
        diversity_threshold=args.diversity_th,
    )
    
    if not elites:
        print("âŒ GAì—ì„œ ìœ íš¨í•œ ì—˜ë¦¬íŠ¸ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. íŒŒë¼ë¯¸í„°/ë°ì´í„°ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return
    
    print(f"   ğŸ† ì§„í™” ì™„ë£Œ! {len(elites)}ê°œ ì—˜ë¦¬íŠ¸ ë°œê²¬")
    print("âœ… 2ë‹¨ê³„ ì™„ë£Œ\n")

    # 3) NewAlphas.py ìƒì„±
    print("ğŸ”¸ 3ë‹¨ê³„: NewAlphas.py ìƒì„±")
    top_elites = elites[:args.topk]
    out_path = os.path.join(BACKEND_MODULE_DIR, "NewAlphas.py")
    
    print(f"   ğŸ“ ìƒìœ„ {len(top_elites)}ê°œ ì•ŒíŒŒë¥¼ NewAlphas.pyë¡œ ì €ì¥ ì¤‘...")
    for i, elite in enumerate(top_elites, 1):
        print(f"      - alphaGA{i:03d}: IC={elite.fitness:.6f}, ìˆ˜ì‹={elite.tree.to_python_expr()[:50]}...")
    
    write_new_alphas_file(top_elites, out_path=out_path)
    print(f"   âœ… NewAlphas.py ìƒì„± ì™„ë£Œ: {out_path}")
    print("âœ… 3ë‹¨ê³„ ì™„ë£Œ\n")

    # 4) ì•ŒíŒŒ CSV ìƒì„± (ë°±í…ŒìŠ¤íŠ¸ìš©)
    print("ğŸ”¸ 4ë‹¨ê³„: ë°±í…ŒìŠ¤íŠ¸ìš© ì•ŒíŒŒ CSV ìƒì„±")
    print("   ğŸ”„ ì „ì²´ ê¸°ê°„ ë°ì´í„°ë¡œ ì•ŒíŒŒ ê³„ì‚° ì¤‘...")
    #    ë°±í…ŒìŠ¤íŠ¸ëŠ” ì „ì²´ ê¸°ê°„ì„ ì“°ëŠ” ê²½ìš°ê°€ ë§ìœ¼ë¯€ë¡œ, ë‚ ì§œ ì œí•œì—†ì´ ì „ì²´ price_dfë¡œ ë‹¤ì‹œ df_data êµ¬ì„±
    df_data_full = make_df_data_from_prices(price_df, None, None)
    top_methods = [f"alphaGA{i:03d}" for i in range(1, len(top_elites)+1)]
    compute_topk_alphas_to_csv(df_data_full, top_methods, args.alpha_out)
    print("âœ… 4ë‹¨ê³„ ì™„ë£Œ\n")

    # 5) (ì˜µì…˜) ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    if args.run_backtest:
        print("ğŸ”¸ 5ë‹¨ê³„: ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰")
        try:
            # 5_results.pyëŠ” backend_moduleì— ìˆë‹¤ê³  ê°€ì •
            results_path = os.path.join(BACKEND_MODULE_DIR, "5_results.py")
            print(f"   ğŸ“ ë°±í…ŒìŠ¤íŠ¸ ëª¨ë“ˆ í™•ì¸: {results_path}")
            
            if not os.path.exists(results_path):
                print(f"âš ï¸ ë°±í…ŒìŠ¤íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {results_path}")
                return
            
            print("   ğŸ“¥ ë°±í…ŒìŠ¤íŠ¸ ëª¨ë“ˆ ë¡œë”© ì¤‘...")
            import importlib.util, types
            spec = importlib.util.spec_from_file_location("results_mod", results_path)
            results_mod = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(results_mod)

            print("   ğŸ”§ ë°±í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
            Lo = getattr(results_mod, "LongOnlyBacktestSystem")
            lob = Lo(price_file=args.price_file, alpha_file=args.alpha_out, config_file=None)
            
            print("   ğŸš€ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘...")
            # ì„¤ì • íŒŒì¼(backtest_config.json) ê¸°ë³¸ê°’ì„ ì“°ë©°, run_backtest íŒŒë¼ë¯¸í„°ëŠ” ë‚´ë¶€ ì„¤ì • ì‚¬ìš©
            lob.run_backtest()
            print("   âœ… ë°±í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
            print("âœ… 5ë‹¨ê³„ ì™„ë£Œ\n")
        except Exception as e:
            print("âš ï¸ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨:", e)
    
    print("ğŸ‰ ëª¨ë“  ë‹¨ê³„ ì™„ë£Œ!")
    print("=" * 60)


if __name__ == "__main__":
    main()
